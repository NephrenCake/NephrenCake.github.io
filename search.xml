<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µ-å®Œç»“ç›®å½•</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-%E5%AE%8C%E7%BB%93%E7%9B%AE%E5%BD%95/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-%E5%AE%8C%E7%BB%93%E7%9B%AE%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µ"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µ" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µ"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µ</h1><p>PyTorchæ·±åº¦å­¦ä¹ å…¥é—¨ç¬”è®°</p><p>æ•™ç¨‹è§†é¢‘ä¼ é€é—¨ï¼š<a href="https://www.bilibili.com/video/BV1Y7411d7Ys?p=13">ã€ŠPyTorchæ·±åº¦å­¦ä¹ å®è·µã€‹å®Œç»“åˆé›†</a></p><table><thead><tr><th align="center"><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part1/">Part1â€”â€”æ¦‚è®º</a></th></tr></thead><tbody><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part2/">Part2â€”â€”çº¿æ€§æ¨¡å‹</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part3/">Part3â€”â€”æ¢¯åº¦ä¸‹é™ç®—æ³•</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part4/">Part4â€”â€”åå‘ä¼ æ’­</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/">Part5â€”â€”çº¿æ€§å›å½’</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part6/">Part6â€”â€”é€»è¾‘æ–¯è’‚å›å½’</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part7/">Part7â€”â€”å¤„ç†å¤šç»´ç‰¹å¾çš„è¾“å…¥</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part8/">Part8â€”â€”åŠ è½½æ•°æ®é›†</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part9/">Part9â€”â€”å¤šåˆ†ç±»é—®é¢˜</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/">Part10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part11/">Part11â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/">Part12â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰</a></strong></td></tr><tr><td align="center"><strong><a href="../PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/">Part13â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰</a></strong></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart13</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart13â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart13â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart13â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart13â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰</h1><h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/image-20210121201135070.png" alt="image-20210121201135070"></p><p>åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/image-20210122101740766.png" alt="image-20210122101740766"></p><h2 id="äººåå¤„ç†"><a href="#äººåå¤„ç†" class="headerlink" title="äººåå¤„ç†"></a>äººåå¤„ç†</h2><ol><li>åˆ‡åˆ†å­—ç¬¦ä¸²</li><li>è½¬ASCIIç </li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/image-20210122103511843.png" alt="image-20210122103511843"></p><ol start="3"><li>å¡«å……</li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/image-20210122103548168.png" alt="image-20210122103548168"></p><ol start="4"><li>è½¬ç½®</li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/image-20210122103627700.png" alt="image-20210122103627700"></p><ol start="5"><li>æ’åº</li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part13/image-20210122103701821.png" alt="image-20210122103701821"></p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pack_padded_sequence</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"></span><br><span class="line">HIDDEN_SIZE = <span class="number">100</span></span><br><span class="line">BATCH_SIZE = <span class="number">256</span></span><br><span class="line">N_LAYER = <span class="number">2</span></span><br><span class="line">N_EPOCHS = <span class="number">100</span></span><br><span class="line">N_CHARS = <span class="number">128</span></span><br><span class="line">USE_GPU = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NameDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, is_train_set=<span class="literal">True</span></span>):</span></span><br><span class="line">        filename = <span class="string">&#x27;../names_train.csv.gz&#x27;</span> <span class="keyword">if</span> is_train_set <span class="keyword">else</span> <span class="string">&#x27;../names_test.csv.gz&#x27;</span></span><br><span class="line">        <span class="keyword">with</span> gzip.<span class="built_in">open</span>(filename, <span class="string">&#x27;rt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            reader = csv.reader(f)</span><br><span class="line">            rows = <span class="built_in">list</span>(reader)</span><br><span class="line">        self.names = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> rows]</span><br><span class="line">        self.<span class="built_in">len</span> = <span class="built_in">len</span>(self.names)</span><br><span class="line">        self.countries = [row[<span class="number">1</span>] <span class="keyword">for</span> row <span class="keyword">in</span> rows]</span><br><span class="line">        self.country_list = <span class="built_in">list</span>(<span class="built_in">sorted</span>(<span class="built_in">set</span>(self.countries)))</span><br><span class="line">        self.country_dict = self.getCountryDict()</span><br><span class="line">        self.country_num = <span class="built_in">len</span>(self.country_list)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.names[index], self.country_dict[self.countries[index]]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getCountryDict</span>(<span class="params">self</span>):</span></span><br><span class="line">        country_dict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> idx, country_name <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.country_list, <span class="number">0</span>):</span><br><span class="line">            country_dict[country_name] = idx</span><br><span class="line">        <span class="keyword">return</span> country_dict</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">idx2country</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.country_list[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getCountriesNum</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.country_num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trainset = NameDataset(is_train_set=<span class="literal">True</span>)</span><br><span class="line">trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>)</span><br><span class="line">testset = NameDataset(is_train_set=<span class="literal">False</span>)</span><br><span class="line">testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=<span class="literal">False</span>)</span><br><span class="line">N_COUNTRY = trainset.getCountriesNum()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNNClassifier</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size, output_size, n_layers=<span class="number">1</span>, bidirectional=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RNNClassifier, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.n_directions = <span class="number">2</span> <span class="keyword">if</span> bidirectional <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.embedding = torch.nn.Embedding(input_size, hidden_size)</span><br><span class="line">        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers,</span><br><span class="line">                                bidirectional=bidirectional)</span><br><span class="line">        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_hidden</span>(<span class="params">self, batch_size</span>):</span></span><br><span class="line">        hidden = torch.zeros(self.n_layers * self.n_directions,</span><br><span class="line">                             batch_size, self.hidden_size)</span><br><span class="line">        <span class="keyword">return</span> create_tensor(hidden)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, seq_lengths</span>):</span></span><br><span class="line">        <span class="comment"># input shape : B x S -&gt; S x B</span></span><br><span class="line">        <span class="built_in">input</span> = <span class="built_in">input</span>.t()</span><br><span class="line">        batch_size = <span class="built_in">input</span>.size(<span class="number">1</span>)</span><br><span class="line">        hidden = self._init_hidden(batch_size)</span><br><span class="line">        embedding = self.embedding(<span class="built_in">input</span>)</span><br><span class="line">        <span class="comment"># pack them up</span></span><br><span class="line">        gru_input = pack_padded_sequence(embedding, seq_lengths)</span><br><span class="line">        output, hidden = self.gru(gru_input, hidden)</span><br><span class="line">        <span class="keyword">if</span> self.n_directions == <span class="number">2</span>:</span><br><span class="line">            hidden_cat = torch.cat([hidden[-<span class="number">1</span>], hidden[-<span class="number">2</span>]], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            hidden_cat = hidden[-<span class="number">1</span>]</span><br><span class="line">        fc_output = self.fc(hidden_cat)</span><br><span class="line">        <span class="keyword">return</span> fc_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">name2list</span>(<span class="params">name</span>):</span></span><br><span class="line">    arr = [<span class="built_in">ord</span>(c) <span class="keyword">for</span> c <span class="keyword">in</span> name]</span><br><span class="line">    <span class="keyword">return</span> arr, <span class="built_in">len</span>(arr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tensor</span>(<span class="params">tensor</span>):</span></span><br><span class="line">    <span class="keyword">if</span> USE_GPU:</span><br><span class="line">        device = torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">        tensor = tensor.to(device)</span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_tensors</span>(<span class="params">names, countries</span>):</span></span><br><span class="line">    sequences_and_lengths = [name2list(name) <span class="keyword">for</span> name <span class="keyword">in</span> names]</span><br><span class="line">    name_sequences = [sl[<span class="number">0</span>] <span class="keyword">for</span> sl <span class="keyword">in</span> sequences_and_lengths]</span><br><span class="line">    seq_lengths = torch.LongTensor([sl[<span class="number">1</span>] <span class="keyword">for</span> sl <span class="keyword">in</span> sequences_and_lengths])</span><br><span class="line">    countries = countries.long()</span><br><span class="line">    <span class="comment"># make tensor of name, BatchSize x SeqLen</span></span><br><span class="line">    seq_tensor = torch.zeros(<span class="built_in">len</span>(name_sequences), seq_lengths.<span class="built_in">max</span>()).long()</span><br><span class="line">    <span class="keyword">for</span> idx, (seq, seq_len) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(name_sequences, seq_lengths), <span class="number">0</span>):</span><br><span class="line">        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)</span><br><span class="line">    <span class="comment"># sort by length to use pack_padded_sequence</span></span><br><span class="line">    seq_lengths, perm_idx = seq_lengths.sort(dim=<span class="number">0</span>, descending=<span class="literal">True</span>)</span><br><span class="line">    seq_tensor = seq_tensor[perm_idx]</span><br><span class="line">    countries = countries[perm_idx]</span><br><span class="line">    <span class="keyword">return</span> create_tensor(seq_tensor), create_tensor(seq_lengths), create_tensor(countries)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">time_since</span>(<span class="params">since</span>):</span></span><br><span class="line">    s = time.time() - since</span><br><span class="line">    m = math.floor(s / <span class="number">60</span>)</span><br><span class="line">    s -= m * <span class="number">60</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;%dm %ds&#x27;</span> % (m, s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainModel</span>():</span></span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, (names, countries) <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">1</span>):</span><br><span class="line">        inputs, seq_lengths, target = make_tensors(names, countries)</span><br><span class="line">        output = classifier(inputs, seq_lengths)</span><br><span class="line">        loss = criterion(output, target)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">f&#x27;[<span class="subst">&#123;time_since(start)&#125;</span>] Epoch <span class="subst">&#123;epoch&#125;</span> &#x27;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            print(<span class="string">f&#x27;[<span class="subst">&#123;i * <span class="built_in">len</span>(inputs)&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(trainset)&#125;</span>] &#x27;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            print(<span class="string">f&#x27;loss=<span class="subst">&#123;total_loss / (i * <span class="built_in">len</span>(inputs))&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testModel</span>():</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="built_in">len</span>(testset)</span><br><span class="line">    print(<span class="string">&quot;evaluating trained model ...&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> i, (names, countries) <span class="keyword">in</span> <span class="built_in">enumerate</span>(testloader, <span class="number">1</span>):</span><br><span class="line">            inputs, seq_lengths, target = make_tensors(names, countries)</span><br><span class="line">            output = classifier(inputs, seq_lengths)</span><br><span class="line">            pred = output.<span class="built_in">max</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>]</span><br><span class="line">            correct += pred.eq(target.view_as(pred)).<span class="built_in">sum</span>().item()</span><br><span class="line">        percent = <span class="string">&#x27;%.2f&#x27;</span> % (<span class="number">100</span> * correct / total)</span><br><span class="line">        print(<span class="string">f&#x27;Test set: Accuracy <span class="subst">&#123;correct&#125;</span>/<span class="subst">&#123;total&#125;</span> <span class="subst">&#123;percent&#125;</span>%&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> correct / total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER)</span><br><span class="line">    <span class="keyword">if</span> USE_GPU:</span><br><span class="line">        device = torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">        classifier.to(device)</span><br><span class="line"></span><br><span class="line">    criterion = torch.nn.CrossEntropyLoss()  <span class="comment"># åšçš„æ˜¯åˆ†ç±»é—®é¢˜ï¼Œç”¨äº¤å‰ç†µ</span></span><br><span class="line">    optimizer = torch.optim.Adam(classifier.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">&quot;Training for %d epochs...&quot;</span> % N_EPOCHS)</span><br><span class="line">    acc_list = []</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, N_EPOCHS + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># Train cycle</span></span><br><span class="line">        trainModel()</span><br><span class="line">        acc = testModel()</span><br><span class="line">        acc_list.append(acc)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart12</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart12â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart12â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart12â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart12â€”â€”å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰</h1><h2 id="å¾ªç¯ç¥ç»ç½‘ç»œRNN"><a href="#å¾ªç¯ç¥ç»ç½‘ç»œRNN" class="headerlink" title="å¾ªç¯ç¥ç»ç½‘ç»œRNN"></a>å¾ªç¯ç¥ç»ç½‘ç»œRNN</h2><p>ä¹‹å‰ä¸€å¼€å§‹ç”¨çš„æ˜¯ç¨ å¯†ç½‘ç»œDNNï¼Œå› ä¸ºæ˜¯å…¨è¿æ¥ï¼Œæ‰€ä»¥å¯¹æ¯ä¸ªå…ƒç´ éƒ½æœ‰ç›¸åº”çš„æƒé‡ï¼Œå› æ­¤å…¶è®¡ç®—é‡æ˜¯è¿œå¤§äºçœ‹ä¼¼å¤æ‚ä½†æ˜¯å…·æœ‰æƒé‡å…±äº«ç‰¹æ€§çš„CNNçš„ã€‚è€ŒRNNå°±æ˜¯å»¶ç»­æƒé‡å…±äº«ç†å¿µçš„ç½‘ç»œã€‚</p><p>RNNä¸»è¦å¤„ç†æœ‰åºåˆ—è¿æ¥çš„æ•°æ®ï¼Œæ¯”å¦‚è‡ªç„¶è¯­è¨€ã€å¤©æ°”ã€è‚¡å¸‚ã€è§†é¢‘ç­‰ã€‚</p><p>RNNæœ¬è´¨æ˜¯ä¸€ä¸ªçº¿æ€§å±‚ï¼Œä¸DNNä¸åŒæ˜¯RNN Cellæ˜¯å…±äº«çš„ã€‚</p><p>ä»å›¾åƒåˆ°æ–‡æœ¬çš„è½¬æ¢ï¼šCNN+FC+RNNã€‚</p><p>å¾ªç¯ç¥ç»ç½‘ç»œçš„æ¿€æ´»å‡½æ•°æ›´å¸¸ç”¨tanhã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/image-20210121142256148.png" alt="image-20210121142256148"></p><p>å¯ä»¥é€‰æ‹©ä½¿ç”¨RNN Cellè‡ªå·±æ„å»ºå¾ªç¯ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨RNNã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/image-20210121145441952.png" alt="image-20210121145441952"></p><h2 id="ç‹¬çƒ­ç¼–ç "><a href="#ç‹¬çƒ­ç¼–ç " class="headerlink" title="ç‹¬çƒ­ç¼–ç "></a>ç‹¬çƒ­ç¼–ç </h2><p>å¤„ç†æ–‡æœ¬ä½¿ç”¨ç‹¬çƒ­ç¼–ç </p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/image-20210121151229487.png" alt="image-20210121151229487"></p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/image-20210121151654777.png" alt="image-20210121151654777"></p><h2 id="åµŒå…¥å±‚"><a href="#åµŒå…¥å±‚" class="headerlink" title="åµŒå…¥å±‚"></a>åµŒå…¥å±‚</h2><p>ç‹¬çƒ­ç¼–ç çš„ç¼ºç‚¹ï¼š</p><ol><li>ç»´åº¦é«˜</li><li>ç¨€ç–</li><li>ç¡¬ç¼–ç </li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/image-20210121153403068.png" alt="image-20210121153403068"></p><p>ä½¿ç”¨Embeddingæ”¹å–„ä¼˜åŒ–</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare dataset</span></span><br><span class="line">num_class = <span class="number">4</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">8</span></span><br><span class="line">embedding_size = <span class="number">10</span></span><br><span class="line">num_layers = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">idx2char = [<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]</span><br><span class="line">x_data = [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># (batch, seq_len)</span></span><br><span class="line">y_data = [<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]  <span class="comment"># (batch * seq_len)</span></span><br><span class="line">inputs = torch.LongTensor(x_data)</span><br><span class="line">labels = torch.LongTensor(y_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># design model using class</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.emb = torch.nn.Embedding(input_size, embedding_size)  <span class="comment"># matrix of Embedding:[input_size, embedding_size]</span></span><br><span class="line">        self.rnn = torch.nn.RNN(input_size=embedding_size,</span><br><span class="line">                                hidden_size=hidden_size,</span><br><span class="line">                                num_layers=num_layers,</span><br><span class="line">                                batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(hidden_size, num_class)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        hidden = torch.zeros(num_layers, x.size(<span class="number">0</span>), hidden_size)</span><br><span class="line">        x = self.emb(</span><br><span class="line">            x)  <span class="comment"># è¿™é‡Œè¾“å…¥éœ€è¦æ˜¯é•¿æ•´å‹longtensorï¼Œè¾“å‡ºä¸º(ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’†ğ’ğ’ƒğ’†ğ’…ğ’…ğ’Šğ’ğ’ˆğ‘ºğ’Šğ’›ğ’†)ï¼Œæ³¨æ„batch_first=True</span></span><br><span class="line">        x, _ = self.rnn(x, hidden)  <span class="comment"># è¾“å‡º(ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†, ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’, ğ’‰ğ’Šğ’…ğ’…ğ’†ğ’ğ‘ºğ’Šğ’›e)</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x.view(-<span class="number">1</span>, num_class)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct loss and optimizer</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># training cycle forward, backward, update</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    outputs = net(inputs)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    _, idx = outputs.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">    idx = idx.data.numpy()</span><br><span class="line">    print(<span class="string">&#x27;Predicted: &#x27;</span>, <span class="string">&#x27;&#x27;</span>.join([idx2char[x] <span class="keyword">for</span> x <span class="keyword">in</span> idx]), end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    print(<span class="string">&#x27;, Epoch [%d/15] loss = %.3f&#x27;</span> % (epoch + <span class="number">1</span>, loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="è¯¾åä½œä¸š"><a href="#è¯¾åä½œä¸š" class="headerlink" title="è¯¾åä½œä¸š"></a>è¯¾åä½œä¸š</h2><p>ä½¿ç”¨LSTMå’ŒGRUè®­ç»ƒæ¨¡å‹</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/image-20210121192740594.png" alt="image-20210121192740594"></p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part12/image-20210121192834591.png" alt="image-20210121192834591"></p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart11</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part11/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part11/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆé«˜çº§ç¯‡ï¼‰</h1><h2 id="Inception"><a href="#Inception" class="headerlink" title="Inception"></a>Inception</h2><p>å¯»æ‰¾è¶…å‚æ•°æ˜¯ååˆ†å›°éš¾çš„ï¼ŒGoogleNetæŠŠä¸åŒçš„æ¨¡å‹ä½œæˆå—Inceptionï¼Œåœ¨è®­ç»ƒæ—¶ä¼˜ç§€çš„è¶…å‚æ•°æ¨¡å—æƒé‡è‡ªç„¶å¢åŠ ã€‚</p><p>Concatenateæ‹¼æ¥å››ä¸ªåˆ†æ”¯ç®—å‡ºæ¥çš„å¼ é‡ã€‚</p><p>ä¸åŒçš„åˆ†æ”¯ï¼Œå¯ä»¥æœ‰ä¸åŒçš„channelï¼Œä½†è¦æœ‰ç›¸åŒçš„widthã€heightã€‚</p><p>poolingä¹Ÿå¯ä»¥è®¾ç½®padding=1ã€stride=1æ¥ä¿è¯è¾“å‡ºå¤§å°ä¸€æ ·ã€‚</p><p>1*1å·ç§¯ï¼Œå…¶æ•°é‡å–å†³äºè¾“å…¥å¼ é‡çš„é€šé“ã€‚</p><p>1*1å·ç§¯çš„ä¿¡æ¯èåˆï¼Œæ˜¯åœ¨æ¯ä¸€ä¸ªåƒç´ ç‚¹å¤šé€šé“æ–¹é¢çš„èåˆã€‚</p><p>1*1å·ç§¯ä¸»è¦è§£å†³è¿ç®—é‡è¿‡å¤§çš„é—®é¢˜ï¼Œå¯ä»¥å‡å°‘ä¸‹ä¸€å±‚è¾“å…¥é€šé“æ•°é‡ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part11/image-20210119191134365.png" alt="GoogleNet"></p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part11/image-20210120113458095.png" alt="image-20210120113458095"></p><p>æœ€åè¾“å‡ºçš„å¤§å°ä¸€èˆ¬ä¼šå»æ‰çº¿æ€§å±‚ï¼Œå…ˆå®ä¾‹åŒ–è·‘ä¸€éè¾“å‡ºsizeã€‚</p><p>åœ¨å†™ç½‘ç»œæ—¶ï¼Œè¦åŠ ä¸Šä¸€ä¸ªå­˜ç›˜åŠŸèƒ½ï¼Œå³æ¯æ¬¡å‡†ç¡®ç‡è¾¾åˆ°æ–°é«˜æ—¶åšä¸€æ¬¡æ¨¡å‹æ•°æ®å¤‡ä»½ï¼Œé˜²æ­¢æ„å¤–ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare dataset</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"><span class="comment"># Composeå‚æ•°åˆ—è¡¨ï¼šè½¬ä¸ºå¼ é‡ï¼›å½’ä¸€åŒ–,å‡å€¼å’Œæ–¹å·®</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])</span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># design model using class</span></span><br><span class="line"><span class="comment"># network in network</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionA</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(InceptionA, self).__init__()</span><br><span class="line">        <span class="comment"># 4æ¡åˆ†æ”¯</span></span><br><span class="line">        <span class="comment"># 1. 1*1å·ç§¯</span></span><br><span class="line">        self.branch1x1 = nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. 1*1å·ç§¯+5*5å·ç§¯</span></span><br><span class="line">        self.branch5x5_1 = nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch5x5_2 = nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)  <span class="comment"># ä¿æŒå›¾åƒå¤§å°ä¸å˜ï¼Œkernel=5ï¼Œåˆ™padding=2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. 1*1å·ç§¯+3*3å·ç§¯+3*3å·ç§¯</span></span><br><span class="line">        self.branch3x3_1 = nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_2 = nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)  <span class="comment"># ä¿æŒå›¾åƒå¤§å°ä¸å˜ï¼Œkernel=3ï¼Œåˆ™padding=1</span></span><br><span class="line">        self.branch3x3_3 = nn.Conv2d(<span class="number">24</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4, æ± åŒ–(å‡½æ•°)+1*1å·ç§¯</span></span><br><span class="line">        self.branch_pool = nn.Conv2d(in_channels, <span class="number">24</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        branch1x1 = self.branch1x1(x)</span><br><span class="line"></span><br><span class="line">        branch5x5 = self.branch5x5_1(x)</span><br><span class="line">        branch5x5 = self.branch5x5_2(branch5x5)</span><br><span class="line"></span><br><span class="line">        branch3x3 = self.branch3x3_1(x)</span><br><span class="line">        branch3x3 = self.branch3x3_2(branch3x3)</span><br><span class="line">        branch3x3 = self.branch3x3_3(branch3x3)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># æ± åŒ–æ˜¯å‡½æ•°ï¼Œä¸éœ€è¦è®­ç»ƒï¼Œåªåœ¨forwardä¸­è°ƒç”¨</span></span><br><span class="line">        <span class="comment"># æ± åŒ–ä¹Ÿå¯ä»¥ä½¿å›¾åƒå¤§å°ä¸å˜ã€‚1. kernel_size=3ï¼Œåˆ™padding=1ï¼›2. stride=1</span></span><br><span class="line">        branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        branch_pool = self.branch_pool(branch_pool)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Concatenate</span></span><br><span class="line">        outputs = [branch1x1, branch5x5, branch3x3, branch_pool]</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">1</span>)  <span class="comment"># b,c,w,h  cå¯¹åº”çš„æ˜¯dim=1ï¼Œæ²¿ç€channelçš„ç»´åº¦æ‹¼æ¥</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">88</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)  <span class="comment"># 88 = 24x3 + 16</span></span><br><span class="line"></span><br><span class="line">        self.incep1 = InceptionA(in_channels=<span class="number">10</span>)  <span class="comment"># ä¸conv1 ä¸­çš„10å¯¹åº”</span></span><br><span class="line">        self.incep2 = InceptionA(in_channels=<span class="number">20</span>)  <span class="comment"># ä¸conv2 ä¸­çš„20å¯¹åº”</span></span><br><span class="line"></span><br><span class="line">        self.mp = nn.MaxPool2d(<span class="number">2</span>)  <span class="comment"># MaxPooling</span></span><br><span class="line">        self.fc = nn.Linear(<span class="number">1408</span>, <span class="number">10</span>)  <span class="comment"># FullConnecting</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        in_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.mp(self.conv1(x)))</span><br><span class="line">        x = self.incep1(x)</span><br><span class="line">        x = F.relu(self.mp(self.conv2(x)))</span><br><span class="line">        x = self.incep2(x)</span><br><span class="line">        x = x.view(in_size, -<span class="number">1</span>)  <span class="comment"># -1æŒ‡åœ¨ä¸å‘Šè¯‰å‡½æ•°æœ‰å¤šå°‘åˆ—çš„æƒ…å†µä¸‹ï¼Œæ ¹æ®åŸtensoræ•°æ®å’Œbatchè‡ªåŠ¨åˆ†é…åˆ—æ•°</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct loss and optimizer</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># training cycle</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># enumerate()ç”¨äºå¯è¿­ä»£\å¯éå†çš„æ•°æ®å¯¹è±¡ç»„åˆä¸ºä¸€ä¸ªç´¢å¼•åºåˆ—ï¼ŒåŒæ—¶åˆ—å‡ºæ•°æ®å’Œæ•°æ®ä¸‹æ ‡</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># dataé‡Œé¢åŒ…å«å›¾åƒæ•°æ®inputs(tensor)å’Œæ ‡ç­¾labels(tensor)</span></span><br><span class="line">        inputs, target = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># update</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            print(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">300</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># ä¸éœ€è¦è®¡ç®—å¼ é‡</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    print(<span class="string">&#x27;accuracy on test set: %d %% &#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>``torch.max()[0]` åªè¿”å›æœ€å¤§å€¼çš„æ¯ä¸ªæ•°</p><p><code>troch.max()[1]</code> åªè¿”å›æœ€å¤§å€¼çš„æ¯ä¸ªç´¢å¼•</p><p><code>torch.max()[1].data</code> åªè¿”å›variableä¸­çš„æ•°æ®éƒ¨åˆ†ï¼ˆå»æ‰Variable containing:ï¼‰</p><p><code>torch.max()[1].data.numpy()</code> æŠŠæ•°æ®è½¬åŒ–æˆnumpy ndarry</p><p><code>torch.max()[1].data.numpy().squeeze()</code> æŠŠæ•°æ®æ¡ç›®ä¸­ç»´åº¦ä¸º1 çš„åˆ é™¤æ‰`</p><h2 id="æ®‹å·®ç½‘ç»œ-Residual-Net"><a href="#æ®‹å·®ç½‘ç»œ-Residual-Net" class="headerlink" title="æ®‹å·®ç½‘ç»œ(Residual Net)"></a>æ®‹å·®ç½‘ç»œ(Residual Net)</h2><p>éšç€ç½‘ç»œå±‚æ•°å¢åŠ ï¼Œè¶Šé è¿‘è¾“å…¥æ¨¡å—çš„æ¢¯åº¦æ›´æ–°å°±è¶Šæ…¢ï¼Œå¾ˆå¯èƒ½å¯¼è‡´<strong>æ¢¯åº¦æ¶ˆå¤±</strong>ã€‚</p><p>ä¸ºäº†è§£å†³æ¢¯åº¦æ¶ˆå¤±ï¼Œä¼šåœ¨æ¿€æ´»ä¹‹å‰åŠ å…¥ä¸€ä¸ªè·³è¿æ¥ã€‚</p><p>åœ¨ä½¿ç”¨Residual Blockæ—¶è¦ä¿æŒè¾“å…¥å’Œè¾“å‡ºé€šé“ç›¸åŒã€‚</p><p>Residual Blockç›¸å½“äºæŠŠä¸€ä¸²Weight LayeråŒ…è£¹èµ·æ¥ã€‚</p><p>å†™ç¥ç»ç½‘ç»œä¹Ÿè¦å†™æµ‹è¯•æ–¹æ³•ï¼Œæ£€éªŒè¾“å‡ºæ˜¯å¦å’Œé¢„è®¡ç›¸åŒï¼Œé€æ­¥å¢åŠ ç½‘ç»œè§„æ¨¡ï¼ˆå¢é‡å¼å¼€å‘ï¼‰ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part11/image-20210120182501998.png" alt="image-20210120182501998"></p><blockquote><ol><li>ä»æ•°å­¦å’Œå·¥ç¨‹å­¦æ–¹é¢é‡æ–°ç†è§£æ·±åº¦å­¦ä¹ ç†è®ºã€‚ã€Šæ·±åº¦å­¦ä¹ ã€‹èŠ±ä¹¦ã€‚</li><li>é€šè¯»PyTorchæ–‡æ¡£ã€‚</li><li>å¤ç°ç»å…¸å·¥ä½œã€è®ºæ–‡ã€‚è¯»ä»£ç â†’å†™ä»£ç </li><li>æ‰©å……è§†é‡</li></ol></blockquote><p>ä¸¤ç¯‡è®ºæ–‡ï¼š</p><ol><li>He K, Zhang X, Ren S, et al. Identity Mappings in Deep Residual Networks[C]</li><li>Huang G, Liu Z, Laurens V D M, et al. Densely Connected Convolutional Networks[J]. 2016:2261-2269.</li></ol>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart10â€”â€”å·ç§¯ç¥ç»ç½‘ç»œï¼ˆåŸºç¡€ç¯‡ï¼‰</h1><h2 id="Basic-CNN"><a href="#Basic-CNN" class="headerlink" title="Basic CNN"></a>Basic CNN</h2><p>CNN(Convolutional Neural Network)ç»“æ„ï¼šç‰¹å¾æå–+åˆ†ç±»ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/image-20210118185651529.png" alt="image-20210118185651529"></p><p>é€šé“(Channel)Ã—çºµè½´(Width)Ã—æ¨ªè½´(Height)ï¼Œèµ·ç‚¹ä¸ºå·¦ä¸Šè§’ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/image-20210118194753606.png" alt="image-20210118194753606"></p><p>Patché€Widthæ‰«æï¼ŒçŸ©é˜µä½œæ•°ä¹˜(å“ˆè¾¾ç›ç§¯)ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/image-20210118195245850.png" alt="image-20210118195245850"></p><p>å¤šé€šé“çš„å·ç§¯ä¸­ï¼Œæ¯ä¸€ä¸ªé€šé“éƒ½è¦é…ä¸€ä¸ªå·ç§¯æ ¸ï¼Œå¹¶ç›¸åŠ ã€‚</p><p>æ·±åº¦å­¦ä¹ é‡Œçš„å·ç§¯æ˜¯æ•°å­¦ä¸­çš„äº’ç›¸å…³ï¼Œä½†æ˜¯æƒ¯ä¾‹ç§°ä¸ºå·ç§¯ï¼Œå’Œæ•°å­¦ä¸­çš„å·ç§¯æœ‰ç‚¹ä¸åŒï¼Œä½†æ˜¯ä¸å½±å“ã€‚</p><p>n*nçš„å·ç§¯æ ¸ï¼Œä¸Šä¸‹å„-(n-1)/2ï¼ŒåŸé•¿å®½-(n-1)ã€‚nä¸€èˆ¬é‡‡ç”¨å¥‡æ•°ï¼Œå·ç§¯å½¢çŠ¶ä¸€èˆ¬éƒ½æ˜¯æ­£æ–¹å½¢ï¼Œåœ¨pytorchä¸­å¥‡å¶ã€é•¿æ–¹å½¢éƒ½è¡Œã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/image-20210118200458601.png" alt="image-20210118200458601"></p><p>æ¯ä¸€ç»„å·ç§¯æ ¸çš„é€šé“æ•°é‡è¦æ±‚å’Œè¾“å…¥é€šé“æ˜¯ä¸€æ ·çš„ã€‚è¿™ç§å·ç§¯æ ¸ç»„çš„æ€»æ•°å’Œè¾“å‡ºé€šé“çš„æ•°é‡æ˜¯ä¸€æ ·çš„ã€‚å·ç§¯è¿‡åï¼Œé€šé“å°±ä¸RGBæ²¡æœ‰å…³ç³»äº†ã€‚</p><p>å·ç§¯(convolution)åï¼ŒC(Channels)å˜ï¼ŒW(width)å’ŒH(Height)å¯å˜å¯ä¸å˜ï¼Œå–å†³äºæ˜¯å¦å¡«å……è¾¹ç¼˜(padding)ï¼Œä¸å¡«å……åˆ™ä¼šæœ‰è¾¹ç¼˜æŸå¤±ã€‚</p><p>å·ç§¯å±‚ï¼šä¿ç•™å›¾åƒçš„ç©ºé—´ä¿¡æ¯ã€‚å·ç§¯æœ¬è´¨ä¸Šä¹Ÿæ˜¯çº¿æ€§è®¡ç®—ï¼Œä¹Ÿæ˜¯å¯ä»¥ä¼˜åŒ–çš„æƒé‡ã€‚</p><p>å·ç§¯ç¥ç»ç½‘ç»œè¦æ±‚è¾“å…¥è¾“å‡ºå±‚æ˜¯å››ç»´å¼ é‡(Batch, Channel, Width, Height)ï¼Œå·ç§¯å±‚æ˜¯(mè¾“å‡ºé€šé“æ•°é‡, nè¾“å…¥é€šé“æ•°é‡, wå·ç§¯æ ¸å®½, hå·ç§¯æ ¸é•¿)ï¼Œå…¨è¿æ¥å±‚çš„è¾“å…¥ä¸è¾“å‡ºéƒ½æ˜¯äºŒç»´å¼ é‡(B, Input_feature)ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/image-20210118200942877.png" alt="image-20210118200942877"></p><p>ä¸‹é‡‡æ ·(subsampling)æˆ–æ± åŒ–(pooling)åï¼ŒCä¸å˜ï¼ŒWå’ŒHå˜æˆ åŸé•¿åº¦/æ± åŒ–é•¿åº¦ã€‚ï¼ˆMaxPool2dæ˜¯ä¸‹é‡‡æ ·å¸¸ç”¨çš„ä¸€ç§ï¼Œn*næœ€å¤§æ± åŒ–é»˜è®¤æ­¥é•¿ä¸ºnï¼‰</p><p>æ± åŒ–å±‚ä¸sigmoidä¸€æ ·ï¼Œæ²¡æœ‰æƒé‡ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/image-20210118222617886.png" alt="image-20210118222617886"></p><p>å·ç§¯(çº¿æ€§å˜æ¢)ï¼Œæ¿€æ´»å‡½æ•°(éçº¿æ€§å˜æ¢)ï¼Œæ± åŒ–ï¼›è¿™ä¸ªè¿‡ç¨‹è‹¥å¹²æ¬¡åï¼Œviewæ‰“å¹³ï¼Œè¿›å…¥å…¨è¿æ¥å±‚ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">in_channels, out_channels = <span class="number">1</span>, <span class="number">10</span></span><br><span class="line">width, height = <span class="number">10</span>, <span class="number">10</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line"><span class="built_in">input</span> = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">         <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">6</span>,</span><br><span class="line">         <span class="number">7</span>, <span class="number">8</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">6</span>,</span><br><span class="line">         <span class="number">6</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">6</span>,</span><br><span class="line">         <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">6</span>,</span><br><span class="line">         <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>,</span><br><span class="line">         <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>,</span><br><span class="line">         <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>,</span><br><span class="line">         <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">6</span>,</span><br><span class="line">         <span class="number">7</span>, <span class="number">8</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">6</span>]</span><br><span class="line"><span class="comment"># view()å°†å…¶è½¬åŒ–æˆ4ç»´</span></span><br><span class="line"><span class="built_in">input</span> = torch.Tensor(<span class="built_in">input</span>).view(batch_size, </span><br><span class="line">                                 in_channels, </span><br><span class="line">                                 width, </span><br><span class="line">                                 height)</span><br><span class="line"><span class="comment"># å·ç§¯æ¨¡å‹çš„æ„é€ å‡½æ•°ä¸­ï¼Œè¾“å…¥é€šé“æ•°é‡åœ¨å‰ï¼Œè¾“å‡ºé€šé“æ•°é‡åœ¨åï¼›ä½†æ˜¯å·ç§¯çš„æƒé‡shapeæ˜¯å…ˆè¾“å‡ºåè¾“å…¥</span></span><br><span class="line"><span class="comment"># paddingè¾¹ç¼˜å¡«å……ï¼Œbiasä¸€èˆ¬å·ç§¯ä¸ç”¨åŠ åç½®ï¼Œstrideæ­¥é•¿ï¼Œkernel_sizeæ ¸å¤§å°</span></span><br><span class="line">conv_layer = torch.nn.Conv2d(in_channels,</span><br><span class="line">                             out_channels,</span><br><span class="line">                             kernel_size=kernel_size)</span><br><span class="line">output = conv_layer(<span class="built_in">input</span>)</span><br><span class="line">print(<span class="built_in">input</span>.shape)  <span class="comment"># torch.Size([1, 1, 10, 10])</span></span><br><span class="line">print(output.shape)  <span class="comment"># torch.Size([1, 10, 8, 8])</span></span><br><span class="line">print(conv_layer.weight.shape)  <span class="comment"># torch.Size([10, 1, 3, 3])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/image-20210119001547566.png" alt="image-20210119001547566"></p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part10/image-20210119002051268.png" alt="image-20210119002051268"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare dataset</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])</span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># design model using class</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)  <span class="comment"># å·ç§¯</span></span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)  <span class="comment"># æ± åŒ–</span></span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)  <span class="comment"># çº¿æ€§</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># flatten data from (n,1,28,28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)  <span class="comment"># å…ˆæ±‚batchï¼Œå¤šå°‘æ¡è®°å½•</span></span><br><span class="line">        x = self.pooling(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pooling(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -<span class="number">1</span>)  <span class="comment"># -1 æ­¤å¤„è‡ªåŠ¨ç®—å‡ºçš„æ˜¯320</span></span><br><span class="line">        <span class="comment"># print(&quot;x.shape&quot;,x.shape)</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model.to(device)  <span class="comment"># GPUåŠ é€Ÿ</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># construct loss and optimizer</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># training cycle forward, backward, update</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            print(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">300</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            images, labels = images.to(device), labels.to(device)</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    print(<span class="string">&#x27;accuracy on test set: %d %% &#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line">    <span class="keyword">return</span> correct / total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    epoch_list = []</span><br><span class="line">    acc_list = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        acc = test()</span><br><span class="line">        epoch_list.append(epoch)</span><br><span class="line">        acc_list.append(acc)</span><br><span class="line"></span><br><span class="line">    plt.plot(epoch_list, acc_list)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart9</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part9/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part9/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart9â€”â€”å¤šåˆ†ç±»é—®é¢˜"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart9â€”â€”å¤šåˆ†ç±»é—®é¢˜" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart9â€”â€”å¤šåˆ†ç±»é—®é¢˜"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart9â€”â€”å¤šåˆ†ç±»é—®é¢˜</h1><h2 id="äºŒåˆ†ç±»ä¸å¤šåˆ†ç±»"><a href="#äºŒåˆ†ç±»ä¸å¤šåˆ†ç±»" class="headerlink" title="äºŒåˆ†ç±»ä¸å¤šåˆ†ç±»"></a>äºŒåˆ†ç±»ä¸å¤šåˆ†ç±»</h2><ol><li><p>å¤šè¾“å‡ºä¹‹é—´ä¼šæœ‰æŠ‘åˆ¶å…³ç³»ï¼Œä¸èƒ½ç”¨äºŒåˆ†ç±»åˆ†åˆ«å¯¹nä¸ªç›®æ ‡è¾“å‡ºnæ¬¡ã€‚</p></li><li><p>äºŒåˆ†ç±»å¯¹0/1åªéœ€è¦æ±‚å¯¹ä¸€ä¸ªçš„æ¦‚ç‡å°±è¡Œï¼Œä½†æ˜¯å¤šåˆ†ç±»éœ€è¦ç ”ç©¶åˆ†å¸ƒå·®å¼‚ã€‚</p></li><li><p>ä¸­é—´å±‚ç”¨Sigmoidå˜æ¢ï¼Œæœ€ç»ˆè¾“å‡ºå±‚ç”¨Softmaxè¾“å‡ºä¸€ä¸ªåˆ†å¸ƒï¼Œå°†æ¯ä¸ªæœ€ç»ˆè¾“å‡ºzéƒ½å˜åŒ–æˆ<strong>å¤§äº0ä¸”å’Œä¸º1</strong>(å…ˆè½¬æ­£ï¼Œå†å½’ä¸€)ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part9/image-20210118152538935.png" alt="image-20210118152538935"></p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part9/image-20210118152129056.png" alt="image-20210118152129056"></p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part9/image-20210118153734193.png" alt="image-20210118153734193"></p></li><li><p>åœ¨ä½¿ç”¨äº¤å‰ç†µæŸå¤±æ—¶ï¼Œæœ€åä¸€å±‚çº¿æ€§è¾“å‡ºä¸ç”¨åšæ¿€æ´»å˜æ¢ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part9/image-20210118153824744.png" alt="image-20210118153824744"></p></li><li><p>è¦ç†è§£ CrossEntropyLoss å’Œ LogSoftmax + NLLLoss ä¹‹é—´çš„åŒºåˆ«</p><p>â€¢ <a href="https://pytorch.org/docs/stable/nn.html#crossentropyloss">https://pytorch.org/docs/stable/nn.html#crossentropyloss</a></p><p>â€¢ <a href="https://pytorch.org/docs/stable/nn.html#nllloss">https://pytorch.org/docs/stable/nn.html#nllloss</a></p></li></ol><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms  <span class="comment"># é’ˆå¯¹å›¾åƒè¿›è¡Œçš„å¤„ç†</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare dataset</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"><span class="comment"># ç¥ç»ç½‘ç»œè¾“å…¥å€¼åœ¨[-1,1]æ•ˆæœæœ€å¥½ï¼Œæœä»æ­£æ€åˆ†å¸ƒ</span></span><br><span class="line"><span class="comment"># æ„å»ºçš„æ˜¯Composeç±»çš„å¯¹è±¡ï¼Œå‚æ•°æ˜¯åˆ—è¡¨[]</span></span><br><span class="line"><span class="comment"># transforms.ToTensor()ï¼šPIL Image =&gt; PyTorch Tensorï¼Œå•é€šé“å˜å¤šé€šé“</span></span><br><span class="line"><span class="comment"># transforms.Normalize((mean,), (std,)ï¼šå½’ä¸€åŒ–ï¼Œæ­£æ€åˆ†å¸ƒéœ€è¦çš„æœŸæœ›å’Œæ ‡å‡†å·®ï¼Œæ˜ å°„åˆ°[0,1]åˆ†å¸ƒã€‚æ•°æ®æ˜¯ç®—å¥½çš„ï¼Œæ¢æˆæ ‡å‡†ä¹‹åå¯ä»¥è§£å†³æ¢¯åº¦çˆ†ç‚¸é—®é¢˜</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])</span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># design model using class</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">512</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.linear4 = torch.nn.Linear(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.linear5 = torch.nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">784</span>)  <span class="comment"># -1è‡ªåŠ¨è·å–mini-batchï¼šNã€‚æŠŠæ ·æœ¬[N,1,28,28]è½¬å˜æˆ[N,784]</span></span><br><span class="line">        x = F.relu(self.linear1(x))</span><br><span class="line">        x = F.relu(self.linear2(x))</span><br><span class="line">        x = F.relu(self.linear3(x))</span><br><span class="line">        x = F.relu(self.linear4(x))</span><br><span class="line">        <span class="keyword">return</span> self.linear5(x)  <span class="comment"># æœ€åä¸€å±‚ä¸åšéçº¿æ€§å˜æ¢</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct loss and optimizer</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)  <span class="comment"># momentumå†²é‡</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># training cycle</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># update</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            print(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">300</span>))</span><br><span class="line">            running_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># åŒ…è£¹çš„ä¸€éƒ¨åˆ†ä¸ä¼šæ„å»ºè®¡ç®—å›¾</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)  <span class="comment"># åˆ—æ˜¯dim=0ï¼Œè¡Œæ˜¯dim=1ã€‚è¿”å›æœ€å¤§å€¼å’Œæœ€å¤§å€¼çš„ä¸‹æ ‡</span></span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()  <span class="comment"># åºåˆ—æ±‚å’Œï¼Œä¸€å…±çŒœå¯¹çš„æ•°é‡</span></span><br><span class="line">    print(<span class="string">&#x27;accuracy on test set: %d %% &#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br><span class="line"></span><br><span class="line"><span class="comment"># [1,   300] loss: 2.244</span></span><br><span class="line"><span class="comment"># [1,   600] loss: 1.005</span></span><br><span class="line"><span class="comment"># [1,   900] loss: 0.437</span></span><br><span class="line"><span class="comment"># ..........................</span></span><br><span class="line"><span class="comment"># [8,   300] loss: 0.045</span></span><br><span class="line"><span class="comment"># [8,   600] loss: 0.051</span></span><br><span class="line"><span class="comment"># [8,   900] loss: 0.048</span></span><br><span class="line"><span class="comment"># accuracy on test set: 97 % </span></span><br><span class="line"><span class="comment"># [9,   300] loss: 0.034</span></span><br><span class="line"><span class="comment"># [9,   600] loss: 0.039</span></span><br><span class="line"><span class="comment"># [9,   900] loss: 0.044</span></span><br><span class="line"><span class="comment"># accuracy on test set: 97 % </span></span><br><span class="line"><span class="comment"># [10,   300] loss: 0.030</span></span><br><span class="line"><span class="comment"># [10,   600] loss: 0.027</span></span><br><span class="line"><span class="comment"># [10,   900] loss: 0.036</span></span><br><span class="line"><span class="comment"># accuracy on test set: 96 %</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li><a href="https://blog.csdn.net/Answer3664/article/details/99460175">torch.no_grad()</a>  <a href="https://blog.csdn.net/ego_bai/article/details/80873242">Pythonä¸­withçš„ç”¨æ³•</a></li><li><a href="https://zhuanlan.zhihu.com/p/105783765?utm_source=com.miui.notes">Pythonä¸­å„ç§ä¸‹åˆ’çº¿çš„æ“ä½œ</a> </li><li><a href="https://blog.csdn.net/Z_lbj/article/details/79766690">torch.max( )çš„ç”¨æ³•</a> <a href="https://blog.csdn.net/qq_40210586/article/details/103874000">torch.max( )ä½¿ç”¨è®²è§£</a></li><li>ç”¨å…¨è¿æ¥ç¥ç»ç½‘ç»œè®­ç»ƒå›¾åƒä¼šå¿½ç•¥å±€éƒ¨ä¿¡æ¯çš„åˆ©ç”¨ï¼Œåœ¨è·ç¦»å¾ˆè¿œçš„ä¸¤ä¸ªç‚¹éƒ½ä¼šäº§ç”Ÿè”ç³»ï¼Œè€Œè¿™ä¸ªæ˜¯æ²¡å¿…è¦çš„ã€‚</li><li>å›¾åƒçš„ç‰¹å¾æå–ï¼šå‚…é‡Œå¶å˜æ¢ï¼ˆç¼ºç‚¹ï¼šéƒ½æ˜¯æ­£å¼¦æ³¢ï¼‰ã€Waveletã€å°æ³¢ã€‚ä½†æ˜¯è¿™äº›éƒ½æ˜¯äººå·¥æå–ã€‚è‡ªåŠ¨æå–çš„æœ‰ï¼šCNN</li></ol>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart8</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part8/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part8/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart8â€”â€”åŠ è½½æ•°æ®é›†"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart8â€”â€”åŠ è½½æ•°æ®é›†" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart8â€”â€”åŠ è½½æ•°æ®é›†"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart8â€”â€”åŠ è½½æ•°æ®é›†</h1><h2 id="Dataset-and-DataLoader"><a href="#Dataset-and-DataLoader" class="headerlink" title="Dataset and DataLoader"></a>Dataset and DataLoader</h2><ol><li><p>Datasetï¼šä¸»è¦æ„é€ æ•°æ®é›†ï¼Œæ”¯æŒç´¢å¼•ã€‚</p></li><li><p>DataLoaderï¼šä¸»è¦èƒ½æ‹¿å‡ºmini-batchï¼Œæ‹¿å‡ºä¸€ç»„ç»„æ•°æ®ä»¥å¿«é€Ÿä½¿ç”¨ã€‚</p><p>æ”¹æˆmini-batchä¹‹åï¼Œè®­ç»ƒå¾ªç¯ä¼šå˜æˆä¸€ä¸ªäºŒå±‚çš„åµŒå¥—å¾ªç¯ï¼Œç¬¬ä¸€å±‚è¿­ä»£epochï¼Œç¬¬äºŒå±‚è¿­ä»£mini-batchã€‚</p></li><li><p>Epochï¼šå°†æ‰€æœ‰çš„æ ·æœ¬éƒ½å‚ä¸äº†ä¸€æ¬¡æ­£å‘ä¼ æ’­ã€è®­ç»ƒï¼Œæ˜¯ä¸€æ¬¡epochã€‚</p></li><li><p>Batch-Sizeï¼šæ¯æ¬¡è®­ç»ƒ(å‰é¦ˆ+åé¦ˆ+æ›´æ–°)æ‰€ç”¨çš„æ ·æœ¬æ•°é‡ã€‚</p></li><li><p>Iterationï¼šbatchåˆ†äº†å¤šå°‘æ‰¹ï¼Œå†…å±‚çš„è¿­ä»£æ‰§è¡Œå¤šå°‘æ¬¡ã€‚ä¾‹å¦‚ï¼š1wä¸ªæ ·æœ¬ï¼Œ1kä¸ªbatchï¼Œiterationä¸º10ã€‚</p></li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part8/image-20210118100748425.png" alt="image-20210118100748425"></p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>å¤„ç†æ•°æ®æ–¹å¼</p><ol><li>å…¨éƒ¨è¯»å–åˆ°å†…å­˜ï¼Œé€‚ç”¨äºå…³ç³»è¡¨æˆ–è€…å°æ‰¹é‡ç»“æ„åŒ–çš„æ•°æ®ã€‚</li><li>å°†æ•°æ®æ–‡ä»¶åˆ†å¼€ï¼Œè·¯å¾„å­˜æ”¾åœ¨åˆ—è¡¨ä¸­æ‰“åŒ…ï¼Œé€‚ç”¨äºå›¾åƒã€éŸ³é¢‘ç­‰éç»“æ„åŒ–æ•°æ®ã€‚</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset  <span class="comment"># Datasetæ˜¯æŠ½è±¡ç±»ï¼Œéœ€è¦ç»§æ‰¿</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># å¤„ç†æ•°æ®</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiabetesDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, filepath</span>):</span>  <span class="comment"># åˆå§‹åŒ–ï¼Œæä¾›æ•°æ®é›†è·¯å¾„åŠ è½½</span></span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]  <span class="comment"># shape(è¡Œæ•°,åˆ—æ•°)æ˜¯å…ƒç»„</span></span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span>  <span class="comment"># è·å–æ•°æ®ç´¢å¼•</span></span><br><span class="line">        <span class="keyword">return</span> self.x_data[index], self.y_data[index]  <span class="comment"># è¿”å›çš„æ˜¯å…ƒç»„</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span>  <span class="comment"># è·å–æ•°æ®æ€»é‡</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = DiabetesDataset(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>)</span><br><span class="line"><span class="comment"># shuffle=Trueæ‰“ä¹±mini-batchä¿è¯éšæœºï¼Œnum_workerså¤šçº¿ç¨‹</span></span><br><span class="line">train_loader = DataLoader(dataset=dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºæ¨¡å‹</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.activate = torch.nn.Sigmoid()  <span class="comment"># æ˜¯æ¨¡å—è€Œä¸æ˜¯å‡½æ•°ï¼Œæ²¡æœ‰å‚æ•°ï¼Œæ²¡æœ‰éœ€è¦è®­ç»ƒçš„åœ°æ–¹ï¼Œåªç”¨æ¥æ„å»ºè®¡ç®—å›¾</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.activate(self.linear1(x))</span><br><span class="line">        x = self.activate(self.linear2(x))</span><br><span class="line">        x = self.activate(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸå¤±&amp;ä¼˜åŒ–</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"><span class="comment"># model.parameters()ä¼šæ‰«æmoduleä¸­çš„æ‰€æœ‰æˆå‘˜ï¼Œå¦‚æœæˆå‘˜ä¸­æœ‰ç›¸åº”æƒé‡ï¼Œé‚£ä¹ˆéƒ½ä¼šå°†ç»“æœåŠ åˆ°è¦è®­ç»ƒçš„å‚æ•°é›†åˆä¸Š</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1</span>)</span><br><span class="line">loss_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¾ªç¯è®­ç»ƒ</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  <span class="comment"># åœ¨windowsç³»ç»Ÿä¸‹è¦ç”¨ifå°è£…è®­ç»ƒå¾ªç¯ï¼Œå¦åˆ™ä¼šæŠ¥é”™</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        loss_sum = <span class="number">0</span></span><br><span class="line">        num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># prepare data</span></span><br><span class="line">            inputs, labels = data  <span class="comment"># æ­¤æ—¶ä¸¤ä¸ªå·²ç»è½¬åŒ–æˆtensor</span></span><br><span class="line">            <span class="comment"># Forward</span></span><br><span class="line">            y_pred = model(inputs)</span><br><span class="line">            loss = criterion(y_pred, labels)</span><br><span class="line">            print(epoch, i, loss.item())</span><br><span class="line"></span><br><span class="line">            loss_sum += loss.item()</span><br><span class="line">            num += <span class="number">1</span></span><br><span class="line">            <span class="comment"># Backward</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="comment"># Update</span></span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">        loss_list.append(loss_sum / num)</span><br><span class="line"></span><br><span class="line">    plt.plot(<span class="built_in">range</span>(<span class="number">100</span>), loss_list)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part8/image-20210118110538070.png" alt="image-20210118110538070"></p><p>äºŒå±‚å¾ªç¯é€Ÿåº¦åè€Œå˜æ…¢äº†ï¼Œæ•ˆç‡ä¹Ÿæ²¡æœ‰å¾ˆå¤§æå‡ï¼Ÿ</p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart7</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part7/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part7/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart7â€”â€”å¤„ç†å¤šç»´ç‰¹å¾çš„è¾“å…¥"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart7â€”â€”å¤„ç†å¤šç»´ç‰¹å¾çš„è¾“å…¥" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart7â€”â€”å¤„ç†å¤šç»´ç‰¹å¾çš„è¾“å…¥"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart7â€”â€”å¤„ç†å¤šç»´ç‰¹å¾çš„è¾“å…¥</h1><h2 id="å¤šç»´ç‰¹å¾è¾“å…¥"><a href="#å¤šç»´ç‰¹å¾è¾“å…¥" class="headerlink" title="å¤šç»´ç‰¹å¾è¾“å…¥"></a>å¤šç»´ç‰¹å¾è¾“å…¥</h2><p>ä»å•ä¸€ç‰¹å¾çš„æ•°æ®ï¼Œè½¬è€Œè¾“å…¥å¤šä¸ºç‰¹å¾çš„æ•°æ®ï¼Œæ¨¡å‹å‘ç”Ÿä»¥ä¸‹æ”¹å˜ï¼š</p><ol><li><p>å¯¹äºæ¯ä¸€æ¡(/ç¬¬iæ¡)æœ‰nä¸ªç‰¹å¾(x1â€¦xn)çš„æ•°æ®ï¼Œåˆ™æœ‰nä¸ªä¸åŒçš„weight(w1â€¦wn)å’Œ1ä¸ªç›¸åŒçš„bias(bå°†è¿›è¡Œå¹¿æ’­)ï¼Œå¹¶é€šè¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œå¾—å‡ºä¸€ä¸ªy_hatï¼ˆå‡è®¾è¾“å‡ºç»´åº¦ä¸º1ï¼‰ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part7/image-20210117203233443.png" alt="image-20210117203233443"></p></li><li><p>å¯¹äºæ¯ä¸ªzn(=xn*wn+b)éƒ½è¦é€šè¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ŒSigmoidå‡½æ•°æ˜¯å¯¹äºæ¯ä¸ªå…ƒç´ çš„ï¼Œç±»ä¼¼äºnumpyã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part7/image-20210117203726634.png" alt="image-20210117203726634"></p></li><li><p>è½¬æ¢æˆçŸ©é˜µè¿ç®—å¯ä»¥å‘æŒ¥cpu/gpuå¹¶è¡Œè¿ç®—çš„ä¼˜åŠ¿ã€‚</p></li><li><p>åœ¨ä¹‹å‰çš„ä»£ç ä¸Šï¼Œæƒ³è¦è¿›è¡Œå¤šç»´è¾“å…¥ï¼Œåªéœ€è¦ä¿®æ”¹æ ·æœ¬ä»¥åŠæ¨¡å‹æ„é€ å‡½æ•°ã€‚</p></li></ol><h2 id="å¢åŠ ç¥ç»ç½‘ç»œå±‚æ•°"><a href="#å¢åŠ ç¥ç»ç½‘ç»œå±‚æ•°" class="headerlink" title="å¢åŠ ç¥ç»ç½‘ç»œå±‚æ•°"></a>å¢åŠ ç¥ç»ç½‘ç»œå±‚æ•°</h2><ol><li>å¦‚ä½•å¢åŠ ç¥ç»ç½‘ç»œå±‚æ•°ï¼Ÿå°†å¤šå±‚æ¨¡å‹è¾“å…¥å’Œè¾“å‡ºï¼Œ<strong>å¤´å°¾ç›¸è¿</strong>ã€‚ä¾‹å¦‚ï¼štorch.nn.Linear(8, 6)ã€torch.nn.Linear(6, 4)ã€torch.nn.Linear(4, 1)ã€‚</li><li>ä»€ä¹ˆæ˜¯çŸ©é˜µï¼ŸçŸ©é˜µæ˜¯<strong>ç©ºé—´å˜æ¢å‡½æ•°</strong>ã€‚ä¾‹å¦‚ï¼šy=A*xï¼Œyæ˜¯MÃ—1çš„çŸ©é˜µï¼Œxæ˜¯NÃ—1çš„çŸ©é˜µï¼ŒAæ˜¯MÃ—Nçš„çŸ©é˜µï¼Œåˆ™Aå°±æ˜¯å°†xä»Nç»´è½¬æ¢åˆ°yè¿™ä¸ªMç»´ç©ºé—´çš„ç©ºé—´å˜æ¢å‡½æ•°ã€‚</li><li>çŸ©é˜µæ˜¯çº¿æ€§å˜æ¢ï¼Œä½†æ˜¯å¾ˆå¤šå®é™…æƒ…å†µéƒ½æ˜¯å¤æ‚ã€éçº¿æ€§çš„ã€‚æ‰€ä»¥ï¼Œéœ€è¦ç”¨å¤šä¸ªçº¿æ€§å˜æ¢å±‚ï¼Œé€šè¿‡æ‰¾åˆ°æœ€ä¼˜çš„æƒé‡ç»„åˆèµ·æ¥ï¼Œæ¥æ¨¡æ‹Ÿéçº¿æ€§çš„å˜æ¢ã€‚<strong>å¯»æ‰¾éçº¿æ€§å˜æ¢å‡½æ•°</strong>ï¼Œå°±æ˜¯ç¥ç»ç½‘ç»œçš„æœ¬è´¨ã€‚</li><li>å¤šå±‚ç¥ç»ç½‘ç»œå¯ä»¥é™ç»´ä¹Ÿå¯ä»¥å‡ç»´ï¼Œè‡³äºå¦‚ä½•è¾¾åˆ°æœ€ä¼˜ï¼Œåˆ™æ˜¯<strong>è¶…å‚æ•°çš„æœç´¢</strong>ã€‚</li><li>ç¥ç»å…ƒã€ç½‘ç»œå±‚æ•°è¶Šå¤šï¼Œå­¦ä¹ èƒ½åŠ›å°±è¶Šå¼ºï¼Œä½†æ˜¯åŒæ—¶è¦å°å¿ƒè¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚è¦å­¦ä¹ æ•°æ®çœŸå€¼å’Œå…·å¤‡æ³›åŒ–çš„èƒ½åŠ›ã€‚</li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part7/image-20210117212227590.png" alt="image-20210117212227590"></p><blockquote><p><strong>èƒ½åœ¨ç¼–ç¨‹é“è·¯ä¸Šç«‹ç¨³è„šè·Ÿçš„æ ¸å¿ƒèƒ½åŠ›ï¼š</strong></p><ol><li>è¯»æ–‡æ¡£</li><li>åŸºæœ¬æ¶æ„ç†å¿µ(cpuã€æ“ä½œç³»ç»Ÿã€ä¸»æœºã€ç¼–è¯‘åŸç†)</li></ol></blockquote><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¤„ç†æ•°æ®</span></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)  <span class="comment"># åˆ†éš”ç¬¦&#x27;,&#x27;ï¼Œå¤§å¤šæ•°æ˜¾å¡åªæ”¯æŒ32ä½float</span></span><br><span class="line">x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])  <span class="comment"># å·¦é—­å³å¼€ï¼Œå–æ‰€æœ‰è¡Œã€ç¬¬ä¸€åˆ—åˆ°æœ€åç¬¬äºŒåˆ—ã€‚torch.from_numpyè¿”å›tensor</span></span><br><span class="line">y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])  <span class="comment"># å–æ‰€æœ‰è¡Œã€æœ€åä¸€åˆ—ã€‚[-1]è¡¨ç¤ºæ‹¿å‡ºæ¥çš„æ˜¯çŸ©é˜µï¼Œ-1è¡¨ç¤ºæ‹¿å‡ºæ¥çš„æ˜¯å‘é‡</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºæ¨¡å‹</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.activate = torch.nn.Sigmoid()  <span class="comment"># æ˜¯æ¨¡å—è€Œä¸æ˜¯å‡½æ•°ï¼Œæ²¡æœ‰å‚æ•°ï¼Œæ²¡æœ‰éœ€è¦è®­ç»ƒçš„åœ°æ–¹ï¼Œåªç”¨æ¥æ„å»ºè®¡ç®—å›¾</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.activate(self.linear1(x))</span><br><span class="line">        x = self.activate(self.linear2(x))</span><br><span class="line">        x = self.activate(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸå¤±&amp;ä¼˜åŒ–</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1.0</span>)</span><br><span class="line">loss_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¾ªç¯è®­ç»ƒ</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500000</span>):</span><br><span class="line">    <span class="comment"># Forward</span></span><br><span class="line">    y_pred = model(x_data)  <span class="comment"># è¿™é‡Œå¹¶æ²¡æœ‰ç”¨åˆ°mini-batch</span></span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    print(epoch, loss.item())</span><br><span class="line">    loss_list.append(loss.item())</span><br><span class="line">    <span class="comment"># Backward</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># Update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">500000</span>), loss_list)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸ¥çœ‹ä¸åŒç½‘ç»œå±‚å‚æ•°</span></span><br><span class="line">layer1_weight = model.linear1.weight.data</span><br><span class="line">layer1_bias = model.linear1.bias.data</span><br><span class="line">print(<span class="string">&quot;layer1_weight&quot;</span>, layer1_weight)</span><br><span class="line">print(<span class="string">&quot;layer1_weight.shape&quot;</span>, layer1_weight.shape)</span><br><span class="line">print(<span class="string">&quot;layer1_bias&quot;</span>, layer1_bias)</span><br><span class="line">print(<span class="string">&quot;layer1_bias.shape&quot;</span>, layer1_bias.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>åœ¨100æ¬¡è®­ç»ƒæ—¶ï¼ŒæŸå¤±å¡åœ¨äº†0.65ã€‚</li><li>åœ¨1wæ¬¡è®­ç»ƒæ—¶ï¼ŒæŸå¤±è·¨è¿‡0.65åœåœ¨äº†0.45ã€‚</li><li>å°†å­¦ä¹ ç‡æå‡åˆ°10.0ï¼Œ1wæ¬¡è®­ç»ƒå¯ä»¥çœ‹å‡ºå›¾åƒéœ‡è¡ï¼Œæ— æ³•æ”¶æ•›ï¼Œä½†æ˜¯æŸå¤±çªç ´0.4ä»¥ä¸‹ã€‚</li><li>å°†å­¦ä¹ ç‡è°ƒæ•´åˆ°1.0ï¼Œ10wæ¬¡è®­ç»ƒï¼ŒæŸå¤±çªç ´0.3ä»¥ä¸‹</li><li>å­¦ä¹ ç‡1.0ï¼Œ50wæ¬¡è®­ç»ƒï¼ŒæŸå¤±è¾¾åˆ°0.28</li><li><a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">pytorchæ¿€æ´»å‡½æ•°æ–‡æ¡£</a></li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part7/image-20210117233025403.png" alt="image-20210117233025403"></p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part7/image-20210117235832948.png" alt="image-20210117235832948"></p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart6</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part6/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part6/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart6â€”â€”é€»è¾‘æ–¯è’‚å›å½’"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart6â€”â€”é€»è¾‘æ–¯è’‚å›å½’" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart6â€”â€”é€»è¾‘æ–¯è’‚å›å½’"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart6â€”â€”é€»è¾‘æ–¯è’‚å›å½’</h1><h2 id="åˆ†ç±»é—®é¢˜"><a href="#åˆ†ç±»é—®é¢˜" class="headerlink" title="åˆ†ç±»é—®é¢˜"></a>åˆ†ç±»é—®é¢˜</h2><p>é€»è¾‘æ–¯è’‚å›å½’æ˜¯å¤„ç†åˆ†ç±»é—®é¢˜ï¼Œè€Œä¸æ˜¯å›å½’ä»»åŠ¡ã€‚</p><p>å¤„ç†åˆ†ç±»é—®é¢˜ï¼Œä¸èƒ½ä½¿ç”¨å›å½’çš„æ€æƒ³ï¼Œå³ä½¿è¾“å‡ºå¯ä»¥ä¸º0æˆ–1ã€‚åŸå› åœ¨äºï¼šè‹¥æœ‰ä¸€ä¸ª0-9ï¼Œ10ä¸ªæ‰‹å†™æ•°å­—çš„åˆ†ç±»é—®é¢˜ï¼Œåœ¨å›å½’æ¨¡å‹ä¸­ï¼Œ1å’Œ0è·ç¦»å¾ˆè¿‘ï¼Œ0å’Œ9ç¦»å¾—å¾ˆè¿œï¼Œä½†æ˜¯åœ¨åˆ†ç±»æ¨¡å‹ä¸­ï¼Œ7å’Œ9çš„ç›¸ä¼¼åº¦å°±æ¯”8ä¸7æˆ–9çš„ç›¸ä¼¼åº¦è¦é«˜ã€‚</p><p>åˆ†ç±»é—®é¢˜æœ¬è´¨ä¸Šè¾“å‡ºçš„æ˜¯æ¦‚ç‡ï¼Œä¾‹å¦‚P(0)ã€P(1)â€¦ã€‚</p><h3 id="äºŒåˆ†ç±»é—®é¢˜"><a href="#äºŒåˆ†ç±»é—®é¢˜" class="headerlink" title="äºŒåˆ†ç±»é—®é¢˜"></a>äºŒåˆ†ç±»é—®é¢˜</h3><p>é€šè¿‡è€ƒè¯•çš„æ¦‚ç‡æ˜¯å¤šå°‘</p><h3 id="å¤šåˆ†ç±»é—®é¢˜"><a href="#å¤šåˆ†ç±»é—®é¢˜" class="headerlink" title="å¤šåˆ†ç±»é—®é¢˜"></a>å¤šåˆ†ç±»é—®é¢˜</h3><p>0-9æ‰‹å†™æ•°å­—æ£€æµ‹åˆ†ç±»</p><h2 id="torchvisionå·¥å…·åŒ…"><a href="#torchvisionå·¥å…·åŒ…" class="headerlink" title="torchvisionå·¥å…·åŒ…"></a>torchvisionå·¥å…·åŒ…</h2><p>æŒ‡å®šç›®å½•ï¼Œè®­ç»ƒ/æµ‹è¯•ï¼Œæ˜¯å¦éœ€è¦ä¸‹è½½</p><p>MNISTã€CIFAR10â€¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">train_set = torchvision.datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>)</span><br><span class="line">test_set = torchvision.datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="é¥±å’Œå‡½æ•°"><a href="#é¥±å’Œå‡½æ•°" class="headerlink" title="é¥±å’Œå‡½æ•°"></a>é¥±å’Œå‡½æ•°</h2><h3 id="é€»è¾‘æ–¯è’‚å‡½æ•°"><a href="#é€»è¾‘æ–¯è’‚å‡½æ•°" class="headerlink" title="é€»è¾‘æ–¯è’‚å‡½æ•°"></a>é€»è¾‘æ–¯è’‚å‡½æ•°</h3><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part6/image-20210117161720715.png" alt="image-20210117161720715"></p><h3 id="å…¶ä»–Sigmoid-functions"><a href="#å…¶ä»–Sigmoid-functions" class="headerlink" title="å…¶ä»–Sigmoid functions"></a>å…¶ä»–Sigmoid functions</h3><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part6/image-20210117161834404.png" alt="image-20210117161834404"></p><h2 id="é€»è¾‘æ–¯è’‚å›å½’"><a href="#é€»è¾‘æ–¯è’‚å›å½’" class="headerlink" title="é€»è¾‘æ–¯è’‚å›å½’"></a>é€»è¾‘æ–¯è’‚å›å½’</h2><ol><li><p>Logistic Regressionç±»ä¼¼äºæ­£æ€åˆ†å¸ƒã€‚</p></li><li><p>Logistic Regressionæ˜¯Sigmoid functionsä¸­æœ€è‘—åçš„ï¼Œæ‰€ä»¥æœ‰äº›åœ°æ–¹ç”¨SigmoidæŒ‡ä»£Logisticã€‚</p></li><li><p>é€»è¾‘æ–¯è’‚å›å½’å’Œçº¿æ€§æ¨¡å‹çš„æ˜æ˜¾åŒºåˆ«æ˜¯åœ¨çº¿æ€§æ¨¡å‹çš„åé¢ï¼Œæ·»åŠ äº†æ¿€æ´»å‡½æ•°(éçº¿æ€§å˜æ¢)ï¼Œå°†y_hatä»£å…¥é€»è¾‘æ–¯è’‚å…¬å¼ä¸­çš„xã€‚</p></li><li><p><a href="https://blog.csdn.net/C_chuxin/article/details/86174807">äº¤å‰ç†µæŸå¤±å‡½æ•°çš„æ¨å¯¼è¿‡ç¨‹ä¸ç›´è§‚ç†è§£</a></p></li><li><p>y_hatæ˜¯é¢„æµ‹çš„å€¼[0,1]ä¹‹é—´çš„æ¦‚ç‡ï¼Œyæ˜¯çœŸå®å€¼ï¼Œé¢„æµ‹ä¸æ ‡ç­¾è¶Šæ¥è¿‘ï¼ŒBCEæŸå¤±è¶Šå°ã€‚</p></li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part6/image-20210117164616620.png" alt="image-20210117164616620"></p><blockquote><p>è¦è®¡ç®—çš„æ˜¯åˆ†å¸ƒçš„å·®å¼‚ï¼Œè€Œä¸æ˜¯æ•°å€¼ä¸Šçš„è·ç¦»</p></blockquote><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><ol><li><a href="https://blog.csdn.net/weixin_42621901/article/details/107664771">torch.sigmoid()ã€torch.nn.Sigmoid()å’Œtorch.nn.functional.sigmoid()ä¸‰è€…ä¹‹é—´çš„åŒºåˆ«</a></li><li>BCELoss(Binary CrossEntropyLoss)æ˜¯CrossEntropyLossçš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œåªç”¨äºäºŒåˆ†ç±»é—®é¢˜ï¼Œè€ŒCrossEntropyLosså¯ä»¥ç”¨äºäºŒåˆ†ç±»ï¼Œä¹Ÿå¯ä»¥ç”¨äºå¤šåˆ†ç±»ã€‚</li><li><a href="https://www.cnblogs.com/samwoog/p/13857843.html">BCEå’ŒCEäº¤å‰ç†µæŸå¤±å‡½æ•°çš„åŒºåˆ«</a></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------Prepare dataset----------------------------#</span></span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">0</span>], [<span class="number">0</span>], [<span class="number">1</span>]])  <span class="comment"># äºŒåˆ†ç±»</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------Design model using Class----------------------------#</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegressionModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LogisticRegressionModel, self).__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># nn.functional.sigmoid is deprecated</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(self.linear(x))  <span class="comment"># æ¿€æ´»å‡½æ•°sigmoidä¸éœ€è¦å‚æ•°è®­ç»ƒï¼Œç›´æ¥è°ƒç”¨</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = LogisticRegressionModel()</span><br><span class="line"><span class="comment"># --------------------------Construct loss and optimizer-----------------------------#</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;sum&#x27;</span>)  <span class="comment"># äº¤å‰ç†µï¼Œsize_average=Falseå·²ç»è¢«å¼ƒç”¨</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># --------------------------Training cycle-----------------------------#</span></span><br><span class="line">loss_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    y_pred = model(x_data)  <span class="comment"># æ­£å‘ä¼ æ’­</span></span><br><span class="line">    loss = criterion(y_pred, y_data)  <span class="comment"># è®¡ç®—æŸå¤±</span></span><br><span class="line">    print(epoch, loss.item())</span><br><span class="line">    loss_list.append(loss.item())  <span class="comment"># ä¿å­˜loss</span></span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()  <span class="comment"># å°†æ¢¯åº¦å½’é›¶</span></span><br><span class="line">    loss.backward()  <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">    optimizer.step()  <span class="comment"># è¿›è¡Œæ›´æ–°</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;w = &#x27;</span>, model.linear.weight.item())</span><br><span class="line">print(<span class="string">&#x27;b = &#x27;</span>, model.linear.bias.item())</span><br><span class="line"></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line">print(<span class="string">&#x27;y_pred = &#x27;</span>, y_test.item())</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1000</span>), loss_list)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># y_pred =  0.8808996081352234</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part6/image-20210117172329760.png" alt="image-20210117172329760"></p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart5</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart5â€”â€”çº¿æ€§å›å½’"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart5â€”â€”çº¿æ€§å›å½’" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart5â€”â€”çº¿æ€§å›å½’"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart5â€”â€”çº¿æ€§å›å½’</h1><h2 id="PyTorchå‘¨æœŸ"><a href="#PyTorchå‘¨æœŸ" class="headerlink" title="PyTorchå‘¨æœŸ"></a>PyTorchå‘¨æœŸ</h2><ol><li>prepare dataset</li><li>design model using Class ç›®çš„æ˜¯ä¸ºäº†å‰é¦ˆforwardï¼Œå³è®¡ç®—y hat(é¢„æµ‹å€¼)</li><li>Construct loss and optimizer (using PyTorch API) å…¶ä¸­ï¼Œè®¡ç®—lossæ˜¯ä¸ºäº†è¿›è¡Œåå‘ä¼ æ’­ï¼Œoptimizeræ˜¯ä¸ºäº†æ›´æ–°æ¢¯åº¦ã€‚</li><li>Training cycle (<u><strong><em>forward,backward,update</em></strong></u>)</li></ol><h2 id="å¹¿æ’­"><a href="#å¹¿æ’­" class="headerlink" title="å¹¿æ’­"></a>å¹¿æ’­</h2><p>åŸæœ¬wåªæ˜¯1Ã—1çš„çŸ©é˜µï¼Œæ¯”å¦‚tensor([0.], requires_grad=True)ï¼Œå¾ˆæœ‰å¯èƒ½è¡Œåˆ—æ•°é‡ä¸xyå¯¹ä¸ä¸Šï¼Œè¿™ä¸ªæ—¶å€™pytorchä¼šè¿›è¡Œ<strong>å¹¿æ’­</strong>ï¼Œå°†w<strong>æ‰©å±•æˆä¸€ä¸ª3Ã—1çŸ©é˜µ</strong>ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/image-20210117122903497.png" alt="image-20210117122903497"></p><blockquote><p>pytorchç›´æ¥å†™â€œ*â€è¡¨ç¤ºçŸ©é˜µ<strong>å¯¹åº”ä½ç½®å…ƒç´ ç›¸ä¹˜</strong>ï¼ˆå“ˆè¾¾ç›ç§¯ï¼‰ï¼Œæ•°å­¦ä¸Šçš„çŸ©é˜µä¹˜æ³•æœ‰å¦å¤–çš„å‡½æ•°torch.matmul</p></blockquote><p>è¿™é‡Œxã€yçš„ç»´åº¦éƒ½æ˜¯1ï¼ˆæœ‰å¯èƒ½ä¸æ˜¯1ï¼‰ï¼Œä½†æ˜¯éƒ½åº”å½“çœ‹æˆä¸€ä¸ª<strong>çŸ©é˜µ</strong>ï¼Œè€Œä¸èƒ½æ˜¯å‘é‡ã€‚</p><blockquote><p>xã€yçš„åˆ—æ˜¯ç»´åº¦/ç‰¹å¾ï¼Œè¡Œæ˜¯è®°å½•/æ ·æœ¬</p></blockquote><h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><ol><li>è¦æŠŠè®¡ç®—æ¨¡å‹å®šä¹‰æˆä¸€ä¸ªç±»ï¼Œ<strong>ç»§æ‰¿äºtorch.nn.Model</strong>ã€‚ï¼ˆnnï¼šneural networkï¼‰</li><li>å¦‚æœæœ‰pytorchæ²¡æœ‰æä¾›çš„éœ€æ±‚ï¼Œæˆ–è€…å…¶æ•ˆç‡ä¸å¤Ÿé«˜ï¼Œå¯ä»¥ä»Functionä¸­ç»§æ‰¿ï¼Œæ„é€ è‡ªå·±çš„è®¡ç®—å—ã€‚</li><li>Linearç±»åŒ…æ‹¬æˆå‘˜å˜é‡weightå’Œbiasï¼Œé»˜è®¤bias=Trueï¼ŒåŒæ ·ç»§æ‰¿äºtorch.nn.Modelï¼Œå¯ä»¥è¿›è¡Œåå‘ä¼ æ’­ã€‚</li><li>æƒé‡æ”¾åœ¨xå³è¾¹ï¼Œæˆ–è€…è½¬ç½®æ”¾åœ¨å·¦è¾¹ã€‚ï¼ˆä¸ç®¡æ€ä¹ˆæ”¾éƒ½æ˜¯ä¸ºäº†å‡‘çŸ©é˜µåŸºæœ¬ç§¯ï¼‰</li><li>çˆ¶ç±»å®ç°äº†callableå‡½æ•°ï¼Œè®©å…¶èƒ½å¤Ÿè¢«è°ƒç”¨ã€‚åœ¨callä¸­ä¼šè°ƒç”¨å‰é¦ˆforward()ï¼Œæ‰€ä»¥å¿…é¡»é‡å†™forward()ã€‚</li></ol><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/image-20210117132843838.png" alt="image-20210117132843838"></p><p>*args, **kwargsçš„ç”¨æ³•ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;args:&#x27;</span>, args)</span><br><span class="line">    print(<span class="string">&#x27;kwargs:&#x27;</span>, kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fun(<span class="number">1</span>, <span class="number">2</span>, <span class="number">7</span>, x=<span class="number">6</span>, y=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># args: (1, 2, 7)</span></span><br><span class="line"><span class="comment"># kwargs: &#123;&#x27;x&#x27;: 6&#125;</span></span><br></pre></td></tr></table></figure><h2 id="æŸå¤±-amp-ä¼˜åŒ–"><a href="#æŸå¤±-amp-ä¼˜åŒ–" class="headerlink" title="æŸå¤±&amp;ä¼˜åŒ–"></a>æŸå¤±&amp;ä¼˜åŒ–</h2><ol><li>è®¡ç®—æŸå¤±ä½¿ç”¨ç°æˆçš„ç±»torch.nn.MSELossã€‚</li><li>ä¸€èˆ¬ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œæ±‚å’Œå¹³å‡æ˜¯æ²¡æœ‰å¿…è¦çš„ï¼Œtorch.nn.MSELoss(size_average=<strong>False</strong>)</li><li>ä½¿ç”¨ç°æˆçš„ä¼˜åŒ–å™¨ç±»torch.optim.SGD</li><li><a href="https://pytorch.org/docs/1.7.0/optim.html">ä¸åŒçš„ä¼˜åŒ–å™¨ï¼Œå®˜æ–¹æ–‡æ¡£</a></li><li>æ§åˆ¶è®­ç»ƒæ¬¡æ•°ï¼Œä¸èƒ½è¿‡å°‘ï¼ˆè®­ç»ƒä¸åˆ°ä½ï¼‰ï¼Œä¹Ÿä¸èƒ½è¿‡å¤šï¼ˆè¿‡æ‹Ÿåˆï¼‰</li></ol><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># å‡†å¤‡æ•°æ®ï¼Œè¦æ˜¯çŸ©é˜µ</span></span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">2.0</span>], [<span class="number">4.0</span>], [<span class="number">6.0</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»ºæ¨¡å‹ï¼Œç»§æ‰¿ã€é‡å†™</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearModel</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LinearModel, self).__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.linear(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆæ¨¡å‹çš„å¯¹è±¡</span></span><br><span class="line">model = LinearModel()</span><br><span class="line">criterion = torch.nn.MSELoss(reduction=<span class="string">&#x27;sum&#x27;</span>)  <span class="comment"># size_average=Falseå·²ç»è¢«å¼ƒç”¨</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">loss_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    y_pred = model(x_data)  <span class="comment"># __call__()è°ƒç”¨forward()æ­£å‘ä¼ æ’­è®¡ç®—é¢„æµ‹å€¼</span></span><br><span class="line">    loss = criterion(y_pred, y_data)  <span class="comment"># è®¡ç®—æŸå¤±</span></span><br><span class="line">    print(epoch, loss.item())  <span class="comment"># å¯ä»¥ç›´æ¥æ‰“å°lossï¼Œå› ä¸ºè°ƒç”¨çš„æ˜¯__str__()ä¸ä¼šäº§ç”Ÿè®¡ç®—å›¾</span></span><br><span class="line">    loss_list.append(loss.item())  <span class="comment"># ä¿å­˜loss</span></span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()  <span class="comment"># å°†æ¢¯åº¦å½’é›¶</span></span><br><span class="line">    loss.backward()  <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">    optimizer.step()  <span class="comment"># è¿›è¡Œæ›´æ–°</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;w = &#x27;</span>, model.linear.weight.item())</span><br><span class="line">print(<span class="string">&#x27;b = &#x27;</span>, model.linear.bias.item())</span><br><span class="line"></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)  <span class="comment"># ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹</span></span><br><span class="line">print(<span class="string">&#x27;y_pred = &#x27;</span>, y_test.item())</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ‰“å°å›¾è¡¨</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">100</span>), loss_list)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="è¯¾åä½œä¸š"><a href="#è¯¾åä½œä¸š" class="headerlink" title="è¯¾åä½œä¸š"></a>è¯¾åä½œä¸š</h2><p>æµ‹è¯•ä¸åŒçš„ä¼˜åŒ–å™¨ã€‚é™¤äº†LBFGSï¼Œåªéœ€è¦ä¿®æ”¹è°ƒç”¨å¯¹åº”ä¼˜åŒ–å™¨çš„æ„é€ å™¨ã€‚</p><h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p>w =  0.20570674538612366</p><p>b =  -0.5057424902915955</p><p>y_pred =  0.31708449125289917</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/image-20210117152240566.png" alt="image-20210117152240566"></p><h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>w =  1.466607928276062</p><p>b =  0.14079217612743378</p><p>y_pred =  6.007224082946777</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/image-20210117152322232.png" alt="image-20210117152322232"></p><h3 id="Adamax"><a href="#Adamax" class="headerlink" title="Adamax"></a>Adamax</h3><p>w =  -0.022818174213171005</p><p>b =  0.9245702028274536</p><p>y_pred =  0.8332974910736084</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/image-20210117152149494.png" alt="image-20210117152149494"></p><h3 id="ASGD"><a href="#ASGD" class="headerlink" title="ASGD"></a>ASGD</h3><p>w =  1.6153326034545898</p><p>b =  0.87442547082901</p><p>y_pred =  7.335755825042725</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/image-20210117151915659.png" alt="image-20210117151915659"></p><h3 id="LBFGS"><a href="#LBFGS" class="headerlink" title="LBFGS"></a>LBFGS</h3><p>ç”±äºLBFGSç®—æ³•éœ€è¦é‡å¤å¤šæ¬¡è®¡ç®—å‡½æ•°ï¼Œå› æ­¤éœ€è¦ä¼ å…¥ä¸€ä¸ªé—­åŒ…å»å…è®¸å®ƒä»¬é‡æ–°è®¡ç®—æ¨¡å‹ã€‚è¿™ä¸ªé—­åŒ…åº”å½“æ¸…ç©ºæ¢¯åº¦ï¼Œ è®¡ç®—æŸå¤±ï¼Œç„¶åè¿”å›ã€‚</p><p>å‚è€ƒ<a href="https://blog.csdn.net/ys1305/article/details/94332643">ä¸€ç¯‡å…³äºä¼˜åŒ–å™¨çš„åšæ–‡</a></p><p>è®­ç»ƒæ¨¡å‹éƒ¨åˆ†ä»£ç åº”ä¿®æ”¹ä¸ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">closure</span>():</span></span><br><span class="line">    optimizer.zero_grad()  <span class="comment"># å°†æ¢¯åº¦å½’é›¶</span></span><br><span class="line">    y_pred = model(x_data)  <span class="comment"># __call__()è°ƒç”¨forward()æ­£å‘ä¼ æ’­è®¡ç®—é¢„æµ‹å€¼</span></span><br><span class="line">    loss = criterion(y_pred, y_data)  <span class="comment"># è®¡ç®—æŸå¤±</span></span><br><span class="line">    print(epoch, loss.item())  <span class="comment"># å¯ä»¥ç›´æ¥æ‰“å°lossï¼Œå› ä¸ºè°ƒç”¨çš„æ˜¯__str__()ä¸ä¼šäº§ç”Ÿè®¡ç®—å›¾</span></span><br><span class="line">    loss_list.append(loss.item())  <span class="comment"># ä¿å­˜loss</span></span><br><span class="line">    loss.backward()  <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    optimizer.step(closure())  <span class="comment"># è¿›è¡Œæ›´æ–°</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>w =  1.7660775184631348</p><p>b =  0.531760573387146</p><p>y_pred =  7.596070766448975</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/image-20210117153648037.png" alt="image-20210117153648037"></p><h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p>w =  1.734222650527954</p><p>b =  0.5857117176055908</p><p>y_pred =  7.522602081298828</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/image-20210117150905304.png" alt="image-20210117150905304"></p><h3 id="Rprop"><a href="#Rprop" class="headerlink" title="Rprop"></a>Rprop</h3><p>w =  1.9997763633728027</p><p>b =  0.0004527860146481544</p><p>y_pred =  7.999558448791504</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/Rprop.png" alt="image-20210117150540886"></p><h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p>w =  1.8483222723007202</p><p>b =  0.3447989821434021</p><p>y_pred =  7.738088130950928</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part5/SGD.png" alt="image-20210117150219223"></p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart4</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part4/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part4/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart4â€”â€”åå‘ä¼ æ’­"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart4â€”â€”åå‘ä¼ æ’­" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart4â€”â€”åå‘ä¼ æ’­"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart4â€”â€”åå‘ä¼ æ’­</h1><p>å¯¹äºç®€å•æ¨¡å‹å¯ä»¥æ‰‹åŠ¨æ±‚è§£æå¼ï¼Œä½†æ˜¯å¯¹äºå¤æ‚æ¨¡å‹æ±‚è§£æå¼å‡ ä¹ä¸å¯èƒ½ã€‚</p><h2 id="è®¡ç®—å›¾"><a href="#è®¡ç®—å›¾" class="headerlink" title="è®¡ç®—å›¾"></a>è®¡ç®—å›¾</h2><p>æ¯ä¸€å±‚ç¥ç»ç½‘ç»œåŒ…æ‹¬ä¸€æ¬¡çŸ©é˜µä¹˜æ³•(Matrix Multiplication)ã€ä¸€æ¬¡å‘é‡åŠ æ³•ã€éçº¿æ€§å˜åŒ–å‡½æ•°(ä¸ºäº†é˜²æ­¢å±•å¼€å‡½æ•°è€Œå¯¼è‡´æ·±å±‚ç¥ç»ç½‘ç»œæ— æ„ä¹‰)</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part4/image-20210116225529823.png" alt="image-20210116225529823"></p><h2 id="é“¾å¼æ³•åˆ™"><a href="#é“¾å¼æ³•åˆ™" class="headerlink" title="é“¾å¼æ³•åˆ™"></a>é“¾å¼æ³•åˆ™</h2><p>åœ¨pytorchä¸­ï¼Œæ¢¯åº¦å­˜åœ¨å˜é‡è€Œä¸æ˜¯è®¡ç®—æ¨¡å—é‡Œã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part4/image-20210116230629292.png" alt="image-20210116230629292"></p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part4/image-20210117091957454.png" alt="image-20210117091957454"></p><p>åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ä¸­ï¼Œè™½ç„¶æœ‰äº›å˜é‡å¯ä»¥ä¸æ±‚å¯¼ï¼Œä½†æ˜¯ä¸€æ ·è¦å…·å¤‡èƒ½å¤Ÿæ±‚å¯¼çš„èƒ½åŠ›ã€‚æ¯”å¦‚xçš„å€¼å°±æœ‰å¯èƒ½æ˜¯å‰ä¸€å±‚ç½‘ç»œçš„y_hatä¼ é€’ä¸‹æ¥çš„ã€‚</p><p>æ ¸å¿ƒåœ¨äºæ¢¯åº¦ï¼Œlossè™½ç„¶ä¸ä¼šä½œä¸ºå˜é‡å‚ä¸è®¡ç®—è¿‡ç¨‹ï¼Œä½†æ˜¯åŒæ ·éœ€è¦ä¿ç•™ï¼Œä½œä¸ºå›¾åƒæ•°æ®æ¥åˆ¤æ–­æœ€ç»ˆæ˜¯å¦æ”¶æ•›ã€‚</p><h2 id="PyTorchå®ç°åå‘ä¼ æ’­"><a href="#PyTorchå®ç°åå‘ä¼ æ’­" class="headerlink" title="PyTorchå®ç°åå‘ä¼ æ’­"></a>PyTorchå®ç°åå‘ä¼ æ’­</h2><p>çº¿æ€§æ¨¡å‹y=w*xï¼Œç”¨pytorchå®ç°åå‘ä¼ æ’­</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>]</span><br><span class="line"></span><br><span class="line">w = torch.Tensor([<span class="number">1.0</span>])  <span class="comment"># dataå¿…é¡»æ˜¯ä¸€ä¸ªåºåˆ—</span></span><br><span class="line">w.requires_grad = <span class="literal">True</span>  <span class="comment"># éœ€è¦è®¡ç®—æ¢¯åº¦</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * w  <span class="comment"># wæ˜¯Tensorï¼Œè¿ç®—ç¬¦é‡è½½ï¼Œxä¹Ÿä¼šè½¬æˆtensor</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y) ** <span class="number">2</span>  <span class="comment"># çœ‹åˆ°ä»£ç ä¸€å®šè¦æœ‰æ„è¯†æƒ³åˆ°å¦‚ä½•æ„å»ºè®¡ç®—å›¾</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;predict (before training)&quot;</span>, <span class="number">4</span>, forward(<span class="number">4</span>).item())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):</span><br><span class="line">        l = loss(x, y)  <span class="comment"># å‰é¦ˆè¿‡ç¨‹ï¼Œæ­£å¼æ„å»ºè®¡ç®—å›¾ï¼Œè®¡ç®—æŸå¤±æ›´æ–°l</span></span><br><span class="line">        l.backward()  <span class="comment"># åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦ï¼Œé‡Šæ”¾è®¡ç®—å›¾</span></span><br><span class="line">        print(<span class="string">&#x27;\tgrad:&#x27;</span>, x, y, w.grad.item())</span><br><span class="line">        w.data = w.data - <span class="number">0.01</span> * w.grad.data  <span class="comment"># æ›´æ–°æƒé‡wï¼Œæ³¨æ„gradä¹Ÿæ˜¯ä¸€ä¸ªtensorï¼Œä¸ä½¿ç”¨.dataçš„è¯ç›¸å½“äºåœ¨æ„å»ºè®¡ç®—å›¾</span></span><br><span class="line"></span><br><span class="line">        w.grad.data.zero_()  <span class="comment"># å°†æ¢¯åº¦w.grad.dataæ¸…é›¶</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;progress:&#x27;</span>, epoch, l.item())  <span class="comment"># å–å‡ºlossä½¿ç”¨l.itemï¼Œä¸è¦ç›´æ¥ä½¿ç”¨lï¼ˆlæ˜¯tensorä¼šæ„å»ºè®¡ç®—å›¾ï¼‰</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;predict (after training)&quot;</span>, <span class="number">4</span>, forward(<span class="number">4</span>).item())</span><br><span class="line"><span class="comment"># predict (after training) 4 7.999998569488525</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="è¯¾åä½œä¸š"><a href="#è¯¾åä½œä¸š" class="headerlink" title="è¯¾åä½œä¸š"></a>è¯¾åä½œä¸š</h2><p>äºŒæ¬¡æ¨¡å‹y=w1<em>xÂ²+w2</em>x+bçš„åå‘ä¼ æ’­</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = x ** 2 + 2 * x + 1</span></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">4.0</span>, <span class="number">9.0</span>, <span class="number">16.0</span>]</span><br><span class="line"></span><br><span class="line">w1 = torch.Tensor([<span class="number">1.0</span>])</span><br><span class="line">w2 = torch.Tensor([<span class="number">1.0</span>])</span><br><span class="line">b = torch.Tensor([<span class="number">1.0</span>])</span><br><span class="line">w1.requires_grad, w2.requires_grad, b.requires_grad = <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> w1 * x * x + w2 * x + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y) ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;predict (before training)&quot;</span>, <span class="number">4</span>, forward(<span class="number">4</span>).item())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):</span><br><span class="line">        l = loss(x, y)  <span class="comment"># å‰é¦ˆè¿‡ç¨‹ï¼Œæ­£å¼æ„å»ºè®¡ç®—å›¾ï¼Œè®¡ç®—æŸå¤±æ›´æ–°l</span></span><br><span class="line">        l.backward()  <span class="comment"># åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦ï¼Œé‡Šæ”¾è®¡ç®—å›¾</span></span><br><span class="line">        print(<span class="string">&#x27;\tgrad:&#x27;</span>, x, y, w1.grad.item(), w2.grad.item(), b.grad.item())</span><br><span class="line">        w1.data = w1.data - <span class="number">0.01</span> * w1.grad.data</span><br><span class="line">        w2.data = w2.data - <span class="number">0.01</span> * w2.grad.data</span><br><span class="line">        b.data = b.data - <span class="number">0.01</span> * b.grad.data</span><br><span class="line">        w1.grad.data.zero_()</span><br><span class="line">        w2.grad.data.zero_()</span><br><span class="line">        b.grad.data.zero_()</span><br><span class="line">    print(<span class="string">&#x27;progress:&#x27;</span>, epoch, l.item())  <span class="comment"># å–å‡ºlossä½¿ç”¨l.itemï¼Œä¸è¦ç›´æ¥ä½¿ç”¨lï¼ˆlæ˜¯tensorä¼šæ„å»ºè®¡ç®—å›¾ï¼‰</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;predict (after training)&quot;</span>, <span class="number">4</span>, forward(<span class="number">4</span>).item())</span><br><span class="line">print(w1.data, w2.data, b.data)</span><br><span class="line"><span class="comment"># predict (after training) 4 25.259323120117188</span></span><br><span class="line"><span class="comment"># tensor([1.1145]) tensor([1.4928]) tensor([1.4557])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>æ”¹äº†ä¸€ä¸‹åŸæœ¬çš„æ•°æ®é›†ï¼Œæ›´ç¬¦åˆäºŒæ¬¡å‡½æ•°ï¼Œä½†æ˜¯å› ä¸ºæ ·æœ¬é‡è¿‡å°‘ï¼Œé¢„æµ‹çš„æƒé‡å¹¶ä¸æ˜¯å¾ˆå¥½ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart3</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part3/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part3/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart3â€”â€”æ¢¯åº¦ä¸‹é™ç®—æ³•"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart3â€”â€”æ¢¯åº¦ä¸‹é™ç®—æ³•" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart3â€”â€”æ¢¯åº¦ä¸‹é™ç®—æ³•"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart3â€”â€”æ¢¯åº¦ä¸‹é™ç®—æ³•</h1><h2 id="ä¼˜åŒ–é—®é¢˜"><a href="#ä¼˜åŒ–é—®é¢˜" class="headerlink" title="ä¼˜åŒ–é—®é¢˜"></a>ä¼˜åŒ–é—®é¢˜</h2><ol><li><p>ä¸Šè®²æ˜¯ç©·ä¸¾æ‰€æœ‰å¯èƒ½å€¼å¹¶è‚‰çœ¼æœç´¢æŸå¤±æœ€ä½ç‚¹ã€‚</p></li><li><p>åˆ†æ²»æ³•å¯èƒ½é”™å¤±å…³é”®ï¼Œæœ€ç»ˆåªæ‰¾åˆ°å±€éƒ¨æœ€ä¼˜</p><blockquote><p>ç©·ä¸¾å’Œåˆ†æ²»éƒ½ä¸èƒ½æœ‰æ•ˆè§£å†³å¤§æ•°æ®</p></blockquote></li><li><p>æ¢¯åº¦(gradient)å†³å®šæƒé‡wå¾€å“ªä¸ªæ–¹å‘èµ°ï¼Œæ¢¯åº¦å³æˆæœ¬å¯¹æƒé‡æ±‚å¯¼ï¼Œä¸ºäº†æ§åˆ¶æ­¥ä¼éœ€è¦è®¾å®šä¸€ä¸ªè¾ƒå°çš„å­¦ä¹ ç‡ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part3/image-20210116203946162.png" alt="image-20210116203946162"></p></li><li><p>åœ¨å¤§é‡çš„å®éªŒä¸­å‘ç°ï¼Œå…¶å®å¾ˆå¤šæƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¾ˆéš¾é™·å…¥åˆ°å±€éƒ¨æœ€ä¼˜ç‚¹ã€‚ä½†æ˜¯å­˜åœ¨å¦å¤–ä¸€ä¸ªé—®é¢˜ï¼Œéç‚¹ã€‚éç‚¹ä¼šå¯¼è‡´æ— æ³•ç»§ç»­è¿­ä»£ï¼Œå¯ä»¥é€‰æ‹©é€šè¿‡å¼•å…¥åŠ¨é‡è§£å†³ã€‚</p></li></ol><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>]</span><br><span class="line">w = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span>(<span class="params">xs, ys</span>):</span></span><br><span class="line">    cost = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(xs, ys):  <span class="comment"># 3è¡Œæ•°æ®</span></span><br><span class="line">        y_pred = forward(x)</span><br><span class="line">        cost += (y_pred - y) ** <span class="number">2</span>  <span class="comment"># ç´¯åŠ æŸå¤±å¹³æ–¹</span></span><br><span class="line">    <span class="keyword">return</span> cost / <span class="built_in">len</span>(xs)  <span class="comment"># å¹³å‡</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">xs, ys</span>):</span></span><br><span class="line">    grad = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(xs, ys):</span><br><span class="line">        grad += <span class="number">2</span> * x * (x * w - y)  <span class="comment"># æˆæœ¬å¯¹æƒé‡æ±‚å¯¼</span></span><br><span class="line">    <span class="keyword">return</span> grad / <span class="built_in">len</span>(xs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Predict(before training)&#x27;</span>, <span class="number">4</span>, forward(<span class="number">4</span>))</span><br><span class="line">mse_list = []  <span class="comment"># ä¿å­˜æŸå¤±çš„å˜åŒ–æ›²çº¿</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    cost_val = cost(x_data, y_data)  <span class="comment"># è®¡ç®—æŸå¤±</span></span><br><span class="line">    mse_list.append(cost_val)  <span class="comment"># è®°å½•æŸå¤±å˜åŒ–</span></span><br><span class="line">    grad_val = gradient(x_data, y_data)  <span class="comment"># è®¡ç®—æ¢¯åº¦</span></span><br><span class="line">    w -= <span class="number">0.01</span> * grad_val  <span class="comment"># æ”¹å–„æƒé‡</span></span><br><span class="line">    print(<span class="string">&#x27;Epoch:&#x27;</span>, epoch, <span class="string">&#x27;w=&#x27;</span>, w, <span class="string">&#x27;loss=&#x27;</span>, cost_val)</span><br><span class="line">print(<span class="string">&#x27;Predict(after training)&#x27;</span>, <span class="number">4</span>, forward(<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å›¾è¡¨æ‰“å°</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">100</span>), mse_list)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part3/image-20210116215632394.png" alt="image-20210116215632394"></p><ol><li>ç»˜å›¾æ—¶æƒ³è¦æ¶ˆé™¤å±€éƒ¨éœ‡è¡ï¼Œå¯ä»¥ä½¿ç”¨æŒ‡æ•°åŠ æƒå‡å€¼æ–¹æ³•ï¼Œä½¿å…¶å˜æˆæ›´åŠ å¹³æ»‘çš„æ›²çº¿</li><li>å¦‚æœè®­ç»ƒçš„å›¾åƒå‘æ•£ï¼Œåˆ™è¡¨æ˜è¿™æ¬¡è®­ç»ƒå¤±è´¥äº†ã€‚å…¶åŸå› æœ‰å¾ˆå¤šï¼Œæ¯”å¦‚ï¼Œå­¦ä¹ ç‡å–å¤ªå¤§ã€‚</li></ol><h2 id="éšæœºæ¢¯åº¦ä¸‹é™"><a href="#éšæœºæ¢¯åº¦ä¸‹é™" class="headerlink" title="éšæœºæ¢¯åº¦ä¸‹é™"></a>éšæœºæ¢¯åº¦ä¸‹é™</h2><p>ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ–¹æ³•æ—¶ï¼Œæ›´åŠ å¸¸ç”¨éšæœºæ¢¯åº¦ä¸‹é™(Stochastic Gradient Descent)ã€‚</p><p>éšæœºæ¢¯åº¦ä¸‹é™ä¹Ÿæ˜¯è·¨è¶Šéç‚¹çš„ä¸€ç§æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥å¤§å¹…å‡å°‘è®¡ç®—é‡ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>]</span><br><span class="line">w = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y) ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * x * (x * w - y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Predict(before training)&#x27;</span>, <span class="number">4</span>, forward(<span class="number">4</span>))</span><br><span class="line">mse_list = []  <span class="comment"># ä¿å­˜æŸå¤±çš„å˜åŒ–æ›²çº¿</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    x, y, i = <span class="number">0</span>, <span class="number">0</span>, random.randint(<span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># æ ·æœ¬åŸæœ¬å°±æ˜¯éšæœºçš„ï¼Œæ‰€ä»¥ä¸éœ€è¦æ‰“ä¹±æ ·æœ¬</span></span><br><span class="line">    <span class="keyword">for</span> m, n, j <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data, <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)):</span><br><span class="line">        <span class="keyword">if</span> j == i:</span><br><span class="line">            x, y = m, n  <span class="comment"># 3ç»„ä¸­éšæœºé€‰å–ä¸€ç»„</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    grad = gradient(x, y)  <span class="comment"># è®¡ç®—æ¢¯åº¦</span></span><br><span class="line">    w -= <span class="number">0.01</span> * grad  <span class="comment"># æ”¹å–„æƒé‡</span></span><br><span class="line">    cost_val = loss(x, y)  <span class="comment"># è®¡ç®—æŸå¤±</span></span><br><span class="line">    mse_list.append(cost_val)  <span class="comment"># è®°å½•æŸå¤±å˜åŒ–</span></span><br><span class="line">    print(<span class="string">&#x27;Epoch:&#x27;</span>, epoch, <span class="string">&#x27;w=&#x27;</span>, w, <span class="string">&#x27;loss=&#x27;</span>, cost_val)</span><br><span class="line">print(<span class="string">&#x27;Predict(after training)&#x27;</span>, <span class="number">4</span>, forward(<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å›¾è¡¨æ‰“å°</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">100</span>), mse_list)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part3/image-20210116222847776.png" alt="image-20210116222847776"></p><p>éšæœºæ¢¯åº¦ä¸‹é™å¯èƒ½äº«å—ä¸åˆ°å¹¶è¡Œè®¡ç®—çš„æ•ˆç‡åŠ æˆï¼Œå› æ­¤ä¼šä½¿ç”¨æŠ˜ä¸­æ–¹æ³•ï¼Œæ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™(Mini-Batch/Batch)</p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart2</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part2/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part2/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart2â€”â€”çº¿æ€§æ¨¡å‹"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart2â€”â€”çº¿æ€§æ¨¡å‹" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart2â€”â€”çº¿æ€§æ¨¡å‹"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart2â€”â€”çº¿æ€§æ¨¡å‹</h1><h2 id="ä¸€èˆ¬è¿‡ç¨‹"><a href="#ä¸€èˆ¬è¿‡ç¨‹" class="headerlink" title="ä¸€èˆ¬è¿‡ç¨‹"></a>ä¸€èˆ¬è¿‡ç¨‹</h2><ol><li>Data Set </li><li>Modelï¼ˆç¥ç»ç½‘ç»œã€å†³ç­–æ ‘ã€æœ´ç´ è´å¶æ–¯ï¼‰</li><li>Trainning</li><li>Infering</li></ol><h2 id="è®­ç»ƒ-amp-æµ‹è¯•"><a href="#è®­ç»ƒ-amp-æµ‹è¯•" class="headerlink" title="è®­ç»ƒ&amp;æµ‹è¯•"></a>è®­ç»ƒ&amp;æµ‹è¯•</h2><h3 id="è®­ç»ƒé›†æ‹†åˆ†"><a href="#è®­ç»ƒé›†æ‹†åˆ†" class="headerlink" title="è®­ç»ƒé›†æ‹†åˆ†"></a>è®­ç»ƒé›†æ‹†åˆ†</h3><p>åœ¨ç«èµ›ä¸­ï¼Œè®­ç»ƒé›†æ˜¯å¯è§çš„ï¼Œæµ‹è¯•é›†ä¸€èˆ¬æ˜¯ä¸å¯è§çš„ã€‚ä¸ºäº†æé«˜æˆ–éªŒè¯æ¨¡å‹çš„å‡†ç¡®åº¦ï¼Œä¸€èˆ¬ä¼šæŠŠæ‰‹ä¸­çš„è®­ç»ƒé›†æ‹†åˆ†ï¼Œä»¥åŠäº¤å‰éªŒè¯ã€‚</p><h3 id="è¿‡æ‹Ÿåˆ"><a href="#è¿‡æ‹Ÿåˆ" class="headerlink" title="è¿‡æ‹Ÿåˆ"></a>è¿‡æ‹Ÿåˆ</h3><p>å½“æ¨¡å‹å¯¹è®­ç»ƒé›†çš„å™ªå£°ä¹Ÿå­¦ä¹ è¿›å»çš„æ—¶å€™ï¼Œå¯¹è®­ç»ƒé›†ä»¥å¤–çš„æ•°æ®å¯èƒ½ä¼šå‡ºç°å‡†ç¡®ç‡ä¸‹é™çš„æƒ…å†µã€‚å› æ­¤ä¸€ä¸ªå¥½çš„æ¨¡å‹éœ€è¦æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p><h2 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h2><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part2/image-20210116101533492.png" alt="image-20210116101533492"></p><p>å¹³å‡å¹³æ–¹è¯¯å·®ï¼ˆMSE MeanSquareErrorï¼‰</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># å‰é¦ˆ</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸå¤±</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y) * (y_pred - y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># å­˜æ”¾ç»“æœï¼Œæ‰€æœ‰æƒé‡å’Œå¯¹åº”çš„å‡æ–¹å·®</span></span><br><span class="line">w_list = []</span><br><span class="line">mse_list = []</span><br><span class="line"><span class="comment"># ç©·ä¸¾æ‰€æœ‰æƒé‡0.0-4.1æ­¥é•¿0.1</span></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> np.arange(<span class="number">0.0</span>, <span class="number">4.1</span>, <span class="number">0.1</span>):</span><br><span class="line">    print(<span class="string">&#x27;w=&#x27;</span>, w)</span><br><span class="line">    l_sum = <span class="number">0</span>  <span class="comment"># æŸå¤±çš„å’Œ</span></span><br><span class="line">    <span class="keyword">for</span> x_val, y_val <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):  <span class="comment"># æ‰“åŒ…ï¼Œä¸€å…±ä¸‰è¡Œ</span></span><br><span class="line">        y_pred_val = forward(x_val)  <span class="comment"># å‰é¦ˆç®—å‡ºæ­¤æƒé‡å’Œæ ·æœ¬å¾—å‡ºçš„é¢„æµ‹å€¼ï¼Œå…¶å®å·²ç»åŒ…å«åœ¨loss()ä¸­ï¼Œåªæ˜¯ä¸ºäº†æ‰“å°</span></span><br><span class="line">        loss_val = loss(x_val, y_val)  <span class="comment"># è®¡ç®—è¯¥æƒé‡é¢„æµ‹å€¼å¾—æŸå¤±</span></span><br><span class="line">        l_sum += loss_val  <span class="comment"># æ±‚æŸå¤±å’Œ</span></span><br><span class="line">        print(<span class="string">&#x27;\t&#x27;</span>, x_val, y_val, y_pred_val, loss_val)  <span class="comment"># å½“å‰çš„xã€yå€¼ã€é¢„æµ‹å€¼ã€æŸå¤±</span></span><br><span class="line">    print(<span class="string">&#x27;MSE=&#x27;</span>, l_sum / <span class="number">3</span>)  <span class="comment"># æ±‚æŸå¤±çš„å¹³å‡</span></span><br><span class="line">    <span class="comment"># ä¿å­˜è®°å½•</span></span><br><span class="line">    w_list.append(w)</span><br><span class="line">    mse_list.append(l_sum / <span class="number">3</span>)</span><br><span class="line"><span class="comment"># å›¾è¡¨æ‰“å°</span></span><br><span class="line">plt.plot(w_list, mse_list)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part2/image-20210116155722125.png" alt="image-20210116155722125"></p><blockquote><p>åšæ·±åº¦å­¦ä¹ è¦å®šæœŸå­˜ç›˜ï¼Œé˜²æ­¢æ„å¤–å¯¼è‡´æ•°æ®ä¸¢å¤±</p></blockquote><h2 id="è¯¾åä½œä¸š"><a href="#è¯¾åä½œä¸š" class="headerlink" title="è¯¾åä½œä¸š"></a>è¯¾åä½œä¸š</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿™é‡Œè®¾å‡½æ•°ä¸ºy=3x+2</span></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">5.0</span>, <span class="number">8.0</span>, <span class="number">11.0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * w + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y) * (y_pred - y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.arange()å·¦é—­å³å¼€ï¼›2.æ‰“å° 0.0ã€1.0 æ—¶åªä¼šæ˜¾ç¤º 0.ã€1.ï¼›3.meshgrid()ä¹‹åwã€béƒ½æ˜¯41*41çŸ©é˜µ</span></span><br><span class="line"><span class="comment"># 4.è¿™é‡Œå‰é¦ˆä¸­æ˜¯çŸ©é˜µç‚¹å¯¹ç‚¹çš„è¿ç®—ï¼Œä½†æ³¨æ„å¹¶ä¸æ˜¯çŸ©é˜µè¿ç®—ï¼Œå¥½å¤„æ˜¯çœå»äº†nå±‚forå¾ªç¯ï¼Œä¸¾ä¾‹ï¼š</span></span><br><span class="line"><span class="comment"># a=[[1 2 3][1 2 3]]</span></span><br><span class="line"><span class="comment"># b=[[7 7 7][8 8 8]]</span></span><br><span class="line"><span class="comment"># a*b=[[ 7 14 21][ 8 16 24]]</span></span><br><span class="line">w_list = np.arange(<span class="number">0.0</span>, <span class="number">4.1</span>, <span class="number">0.1</span>)</span><br><span class="line">b_list = np.arange(<span class="number">0.0</span>, <span class="number">4.1</span>, <span class="number">0.1</span>)</span><br><span class="line">w, b = np.meshgrid(w_list, b_list)</span><br><span class="line"></span><br><span class="line">l_sum = <span class="number">0</span>  <span class="comment"># æŸå¤±çš„å’Œ</span></span><br><span class="line"><span class="keyword">for</span> x_val, y_val <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):  <span class="comment"># éå†ä¸‰æ¬¡</span></span><br><span class="line">    <span class="comment"># y_pred_valã€loss_valéƒ½æ˜¯41*41çš„çŸ©é˜µï¼Œå³41ä¸ªwå’Œ41ä¸ªbç»„åˆçš„é¢„æµ‹ç»“æœå’ŒæŸå¤±</span></span><br><span class="line">    y_pred_val = forward(x_val)</span><br><span class="line">    loss_val = loss(x_val, y_val)</span><br><span class="line">    l_sum += loss_val</span><br><span class="line">    print(<span class="string">&#x27;\nx_valï¼š&#x27;</span>, x_val,<span class="string">&#x27;\ny_valï¼š&#x27;</span>, y_val, <span class="string">&#x27;\ny_pred_valï¼š&#x27;</span>,y_pred_val, <span class="string">&#x27;\nloss_valï¼š&#x27;</span>,loss_val)  <span class="comment"># å½“å‰çš„xã€yå€¼ã€é¢„æµ‹å€¼ã€æŸå¤±</span></span><br><span class="line">mse_list = l_sum / <span class="number">3</span></span><br><span class="line"><span class="comment"># mse_listä¹Ÿæ˜¯ä¸€ä¸ªndarrayç±»å‹çš„41*41çŸ©é˜µ</span></span><br><span class="line">print(<span class="string">&#x27;MSE=&#x27;</span>, mse_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3då›¾è¡¨</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(w, b, mse_list)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿™é‡Œè®¾å‡½æ•°ä¸ºy=3x+2</span></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">5.0</span>, <span class="number">8.0</span>, <span class="number">11.0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * w + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y) * (y_pred - y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿™é‡Œéƒ½æ˜¯çŸ©é˜µçš„è¿ç®—</span></span><br><span class="line"><span class="comment"># 1.arange()å·¦é—­å³å¼€ï¼›2.æ‰“å° 0.0ã€1.0 æ—¶åªä¼šæ˜¾ç¤º 0.ã€1.ï¼›3.meshgridä¹‹åwã€béƒ½æ˜¯41*41çŸ©é˜µ</span></span><br><span class="line">w_list = np.arange(<span class="number">0.0</span>, <span class="number">4.1</span>, <span class="number">0.1</span>)</span><br><span class="line">b_list = np.arange(<span class="number">0.0</span>, <span class="number">4.1</span>, <span class="number">0.1</span>)</span><br><span class="line">w, b = np.meshgrid(w_list, b_list)</span><br><span class="line"></span><br><span class="line">l_sum = <span class="number">0</span>  <span class="comment"># æŸå¤±çš„å’Œ</span></span><br><span class="line"><span class="keyword">for</span> x_val, y_val <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):  <span class="comment"># éå†ä¸‰æ¬¡</span></span><br><span class="line">    y_pred_val = forward(x_val)</span><br><span class="line">    loss_val = loss(x_val, y_val)</span><br><span class="line">    l_sum += loss_val</span><br><span class="line">    print(<span class="string">&#x27;\nx_valï¼š&#x27;</span>, x_val,<span class="string">&#x27;\ny_valï¼š&#x27;</span>, y_val, <span class="string">&#x27;\ny_pred_valï¼š&#x27;</span>,y_pred_val, <span class="string">&#x27;\nloss_valï¼š&#x27;</span>,loss_val)  <span class="comment"># å½“å‰çš„xã€yå€¼ã€é¢„æµ‹å€¼ã€æŸå¤±</span></span><br><span class="line">mse_list = l_sum / <span class="number">3</span></span><br><span class="line"><span class="comment"># mse_listä¹Ÿæ˜¯ä¸€ä¸ªndarrayç±»å‹çš„41*41çŸ©é˜µ</span></span><br><span class="line">print(<span class="string">&#x27;MSE=&#x27;</span>, mse_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3då›¾è¡¨</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(w, b, mse_list)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part2/image-20210116155626917.png" alt="image-20210116155626917"></p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart1</title>
      <link href="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part1/"/>
      <url>/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part1/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart1â€”â€”æ¦‚è®º"><a href="#PyTorchæ·±åº¦å­¦ä¹ å®è·µPart1â€”â€”æ¦‚è®º" class="headerlink" title="PyTorchæ·±åº¦å­¦ä¹ å®è·µPart1â€”â€”æ¦‚è®º"></a>PyTorchæ·±åº¦å­¦ä¹ å®è·µPart1â€”â€”æ¦‚è®º</h1><h2 id="æŠ€æœ¯æˆç†Ÿåº¦æ›²çº¿"><a href="#æŠ€æœ¯æˆç†Ÿåº¦æ›²çº¿" class="headerlink" title="æŠ€æœ¯æˆç†Ÿåº¦æ›²çº¿"></a>æŠ€æœ¯æˆç†Ÿåº¦æ›²çº¿</h2><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part1/3b87e950352ac65ca9eb5abaa5e3f21692138a21.jpeg" alt="æŠ€æœ¯æˆç†Ÿåº¦æ›²çº¿"></p><p><strong>ç§‘æŠ€è¯ç”Ÿçš„ä¿ƒåŠ¨æœŸ</strong> (Technology Trigger)ï¼šåœ¨æ­¤é˜¶æ®µï¼Œéšç€åª’ä½“å¤§è‚†çš„æŠ¥é“è¿‡åº¦ï¼Œéç†æ€§çš„æ¸²æŸ“ï¼Œäº§å“çš„çŸ¥ååº¦æ— æ‰€ä¸åœ¨ï¼Œç„¶è€Œéšç€è¿™ä¸ªç§‘æŠ€çš„ç¼ºç‚¹ã€é—®é¢˜ã€é™åˆ¶å‡ºç°ï¼Œå¤±è´¥çš„æ¡ˆä¾‹å¤§äºæˆåŠŸçš„æ¡ˆä¾‹ï¼Œä¾‹å¦‚:.comå…¬å¸ 1998~2000å¹´ä¹‹é—´çš„éç†æ€§ç–¯ç‹‚é£™å‡æœŸã€‚</p><p><strong>è¿‡é«˜æœŸæœ›çš„å³°å€¼</strong>ï¼ˆPeak of Inflated Expectationsï¼‰ï¼šæ—©æœŸå…¬ä¼—çš„è¿‡åˆ†å…³æ³¨æ¼”ç»å‡ºäº†ä¸€ç³»åˆ—æˆåŠŸçš„æ•…äº‹â€”â€”å½“ç„¶åŒæ—¶ä¹Ÿæœ‰ä¼—å¤šå¤±è´¥çš„ä¾‹å­ã€‚å¯¹äºå¤±è´¥ï¼Œæœ‰äº›å…¬å¸é‡‡å–äº†è¡¥æ•‘æªæ–½ï¼Œè€Œå¤§éƒ¨åˆ†å´æ— åŠ¨äºè¡·ã€‚</p><p><strong>æ³¡æ²«åŒ–çš„åº•è°·æœŸ</strong> (Trough of Disillusionment)ï¼šåœ¨å†ç»å‰é¢é˜¶æ®µæ‰€å­˜æ´»çš„ç§‘æŠ€ç»è¿‡å¤šæ–¹æ‰å®æœ‰é‡ç‚¹çš„è¯•éªŒï¼Œè€Œå¯¹æ­¤ç§‘æŠ€çš„é€‚ç”¨èŒƒå›´åŠé™åˆ¶æ˜¯ä»¥å®¢è§‚çš„å¹¶å®é™…çš„äº†è§£ï¼ŒæˆåŠŸå¹¶èƒ½å­˜æ´»çš„ç»è¥æ¨¡å¼é€æ¸æˆé•¿ã€‚</p><p><strong>ç¨³æ­¥çˆ¬å‡çš„å…‰æ˜æœŸ</strong> (Slope of Enlightenment)ï¼šåœ¨æ­¤é˜¶æ®µï¼Œæœ‰ä¸€æ–°ç§‘æŠ€çš„è¯ç”Ÿï¼Œåœ¨å¸‚é¢ä¸Šå—åˆ°ä¸»è¦åª’ä½“ä¸ä¸šç•Œé«˜åº¦çš„æ³¨æ„ï¼Œä¾‹å¦‚:1996å¹´çš„Internet ï¼ŒWebã€‚</p><p><strong>å®è´¨ç”Ÿäº§çš„é«˜å³°æœŸ</strong> (Plateau of Productivity)ï¼šåœ¨æ­¤é˜¶æ®µï¼Œæ–°ç§‘æŠ€äº§ç”Ÿçš„åˆ©ç›Šä¸æ½œåŠ›è¢«å¸‚åœºå®é™…æ¥å—ï¼Œå®è´¨æ”¯æ´æ­¤ç»è¥æ¨¡å¼çš„å·¥å…·ã€æ–¹æ³•è®ºç»è¿‡æ•°ä»£çš„æ¼”è¿›ï¼Œè¿›å…¥äº†éå¸¸æˆç†Ÿçš„é˜¶æ®µã€‚</p><blockquote><p>åœ¨ä½¿ç”¨pytorchæˆ–ä¸€ç³»åˆ—æ–°æŠ€æœ¯çš„æ—¶å€™ï¼Œä¸€å®šè¦å­¦ä¼šçœ‹å®˜æ–¹æ–‡æ¡£ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„èƒ½åŠ›ï¼</p></blockquote><h2 id="äººå·¥æ™ºèƒ½"><a href="#äººå·¥æ™ºèƒ½" class="headerlink" title="äººå·¥æ™ºèƒ½"></a>äººå·¥æ™ºèƒ½</h2><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part1/image-20210115233930514.png" alt="AIæŠ€æœ¯"></p><p>AIé™¤äº†machine learningä¹‹å¤–è¿˜æœ‰æœºå™¨è§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†nlpã€å› æœæ¨æ–­ç­‰ã€‚</p><p>æœºå™¨å­¦ä¹ å¤§éƒ¨åˆ†éƒ½æ˜¯ç›‘ç£å­¦ä¹ ï¼Œå³ç”¨ä¸€ç»„æ ‡ç­¾è¿‡çš„å€¼è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚</p><p>æœºå™¨å­¦ä¹ ä¸­çš„ç®—æ³•åŒºåˆ«äºæ™®é€šçš„ç®—æ³•ï¼ˆç©·ä¸¾ã€è´ªå¿ƒç­‰ï¼‰ï¼Œæ˜¯é€šè¿‡æ•°æ®è®­ç»ƒå¹¶éªŒè¯å¾—å‡ºä¸€ä¸ªå¥½ç”¨çš„æ¨¡å‹ï¼Œå…¶è®¡ç®—è¿‡ç¨‹æ¥è‡ªäºæ•°æ®è€Œä¸æ˜¯äººå·¥çš„è®¾è®¡ã€‚</p><p>æ·±åº¦å­¦ä¹ ä»æ¨¡å‹ä¸Šçœ‹ç”¨çš„æ˜¯ç¥ç»ç½‘ç»œï¼Œä»ç›®æ ‡ä¸Šçœ‹å±äºè¡¨ç¤ºå­¦ä¹ çš„åˆ†æ”¯ã€‚æ–¹æ³•æœ‰ï¼Œå¤šå±‚æ„ŸçŸ¥æœºã€å·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œç­‰ã€‚</p><h2 id="ç»´åº¦è¯…å’’"><a href="#ç»´åº¦è¯…å’’" class="headerlink" title="ç»´åº¦è¯…å’’"></a>ç»´åº¦è¯…å’’</h2><p>éšç€featureä¸Šå‡ï¼Œä¸ºäº†ä¿æŒå‡†ç¡®æ€§ï¼Œå…¶æ‰€éœ€çš„æ•°æ®é‡å°†æ€¥é€Ÿä¸Šå‡ï¼Œç„¶è€Œè·å–æ‰“è¿‡æ ‡ç­¾çš„æ•°æ®ï¼Œå·¥ä½œé‡å¤§ã€æˆæœ¬é«˜ã€‚</p><p>n<em>1çš„å‘é‡é‡‡æ ·ç‚¹éœ€è¦ä¸€ä¸ª3</em>nçš„çŸ©é˜µæ¥æ˜ å°„åˆ°3*1çš„å‘é‡ï¼Œå®ç°é™ç»´ï¼ˆPCAä¸»æˆæˆåˆ†åˆ†æï¼‰ã€‚ä½†æ˜¯é™ç»´çš„åŒæ—¶ä¹Ÿè¦å°½é‡ä¿è¯é«˜ç»´ç©ºé—´çš„åº¦é‡ä¿¡æ¯ï¼Œè¿™ä¸ªè¿‡ç¨‹å«åšè¡¨ç¤ºå­¦ä¹ ï¼ˆPresentï¼‰ã€‚è¿™ä¸ªæ•°æ®åˆ†å¸ƒæ˜¯åœ¨é«˜ç»´ç©ºé—´é‡Œçš„ä½ç»´æµè¡Œï¼ˆManifoldï¼‰ã€‚</p><h2 id="å‘å±•å†å²"><a href="#å‘å±•å†å²" class="headerlink" title="å‘å±•å†å²"></a>å‘å±•å†å²</h2><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part1/image-20210116083615697.png" alt="image-20210116083615697"></p><h2 id="ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»"><a href="#ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»" class="headerlink" title="ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»"></a>ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»</h2><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part1/image-20210116083809610.png" alt="image-20210116083809610"></p><h2 id="ç¥ç»ç½‘ç»œå‘å±•"><a href="#ç¥ç»ç½‘ç»œå‘å±•" class="headerlink" title="ç¥ç»ç½‘ç»œå‘å±•"></a>ç¥ç»ç½‘ç»œå‘å±•</h2><p>ç”±ç”Ÿç‰©å®éªŒå¾—å‡ºï¼Œå“ºä¹³åŠ¨ç‰©çš„è§†è§‰ç¥ç»æ˜¯åˆ†å±‚çš„ã€‚æµ…å±‚åªæ£€æµ‹ç‰©ä½“çš„è¿åŠ¨ç­‰ï¼Œæ·±å±‚æ‰å¼€å§‹è¯†åˆ«ç‰©ä½“çš„åˆ†ç±»ã€‚ç”±æ­¤å‡ºç°äº†æ„ŸçŸ¥æœºã€‚</p><p>ç°åœ¨ç¥ç»ç½‘ç»œæ—©å·²ä¸æ˜¯ç”Ÿç‰©çš„èŒƒç•´ï¼Œè€Œæ˜¯å·¥ç¨‹ä¸æ•°å­¦æ–¹é¢ã€‚</p><p>çœŸæ­£è®©ç¥ç»ç½‘ç»œå‘å±•èµ·æ¥çš„æ˜¯åå‘ä¼ æ’­ï¼ˆBack Propagationï¼‰ï¼Œå…¶æ ¸å¿ƒåœ¨äºè®¡ç®—å›¾ã€‚</p><p><img src="/2021/01/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5Part1/image-20210116090403146.png" alt="image-20210116090403146"></p>]]></content>
      
      
      <categories>
          
          <category> PyTorchæ·±åº¦å­¦ä¹ å®è·µ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexoé™æ€åšå®¢æ­å»ºå’Œéƒ¨ç½²</title>
      <link href="/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/"/>
      <url>/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="è½¯ä»¶å®‰è£…"><a href="#è½¯ä»¶å®‰è£…" class="headerlink" title="è½¯ä»¶å®‰è£…"></a>è½¯ä»¶å®‰è£…</h1><h2 id="Nodejs"><a href="#Nodejs" class="headerlink" title="Nodejs"></a>Nodejs</h2><p><a href="https://nodejs.org/en/">Node.js</a></p><ul><li><code>node -v</code>ç¡®è®¤nodejsç‰ˆæœ¬ï¼Œå®‰è£…æˆåŠŸ</li></ul><h2 id="Git-Bash"><a href="#Git-Bash" class="headerlink" title="Git Bash"></a>Git Bash</h2><p><a href="https://www.git-scm.com/download/win">Downloading Git</a></p><ul><li><code>git --version</code>ç¡®è®¤nodejsç‰ˆæœ¬ï¼Œå®‰è£…æˆåŠŸ</li></ul><blockquote><p>nodejså’Œgitè‡ªå·±é€‰å¥½å®‰è£…ä½ç½®ä¹‹åæ— è„‘ä¸‹ä¸€æ­¥å°±è¡Œã€‚ä»¥ä¸‹éƒ½ä»¥æˆ‘ä¸ªäººçš„å®‰è£…ç›®å½•ï¼ˆD:\ProgrammingKits\nodejs å’Œ D:\ProgrammingKits\Gitï¼‰ä¸ºå‰æï¼Œè¯·å¤§å®¶å„è‡ªä¿®æ”¹ä¸ºè‡ªå·±çš„è·¯å¾„ã€‚</p></blockquote><h1 id="Nodejsæ’ä»¶å®‰è£…"><a href="#Nodejsæ’ä»¶å®‰è£…" class="headerlink" title="Nodejsæ’ä»¶å®‰è£…"></a>Nodejsæ’ä»¶å®‰è£…</h1><ul><li><p>æœ€æ–°çš„Nodejsè‡ªå¸¦npmï¼Œä½†æ˜¯é»˜è®¤å®‰è£…å’Œç¼“å­˜åœ°å€ä¸åœ¨Nodejsæ ¹ç›®å½•ä¸‹</p><p>  npmçš„é»˜è®¤å…¨å±€æ¨¡å—çš„å®‰è£…åœ°å€æ˜¯ C:\Users\Administrator\AppData\Roaming\npm</p><p>  npmçš„é»˜è®¤ç¼“å­˜çš„åœ°å€æ˜¯ C:\Users\Administrator\AppData\Roaming\npm_cache</p></li></ul><p>é¦–å…ˆä¿®æ”¹nodejsçš„prefixï¼ˆå…¨å±€ï¼‰å’Œcacheï¼ˆç¼“å­˜ï¼‰æ–‡ä»¶å¤¹åœ°å€</p><ul><li>è¿è¡Œ<code>npm config set cache &quot;D:\ProgrammingKits\nodejs\node_cache&quot;</code>è®¾ç½®ç¼“å­˜æ–‡ä»¶å¤¹</li><li>è¿è¡Œ<code>npm config set prefix &quot;D:\ProgrammingKits\nodejs\nodejs&quot;</code>è®¾ç½®å…¨å±€æ¨¡å—å­˜æ”¾è·¯å¾„ã€‚</li></ul><p><del>è¿™ç§æ–¹æ³•å¯ä»¥ä¸ç”¨åƒ<code>npm config set prefix &quot;D:\ProgrammingKits\nodejs\node_global&quot;</code>éœ€è¦ä¿®æ”¹ç¯å¢ƒå˜é‡ã€‚</del></p><p>ä»¥ånpmå’Œcnpmå®‰è£…çš„å…¨å±€æ¨¡å—éƒ½ä¼šè¢«æ”¾åˆ° D:\ProgrammingKits\nodejs\node_modules ä¸‹ï¼Œè·Ÿè‡ªå¸¦çš„npmæ¨¡å—æœ¬ä½“åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ã€‚</p><h2 id="cnpm"><a href="#cnpm" class="headerlink" title="cnpm"></a>cnpm</h2><p>è¿™é‡Œå®‰è£…æ·˜å®çš„cnpmåŒ…ç®¡ç†å™¨ï¼Œä»¥æé«˜ä¸‹è½½é€Ÿåº¦ã€‚</p><ul><li>è¿è¡Œ<code>npm install -g cnpm --registry=http://registry.npm.taobao.org</code></li><li><code>cnpm -v</code> ç¡®è®¤cnpmç‰ˆæœ¬ï¼Œå®‰è£…æˆåŠŸ</li></ul><h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><p>é™æ€åšå®¢æ¡†æ¶</p><ul><li>è¿è¡Œ<code>cnpm install -g hexo-cli</code> å®‰è£…hexoæ¡†æ¶</li><li><code>hexo -v</code>ç¡®è®¤hexoç‰ˆæœ¬ï¼Œå®‰è£…æˆåŠŸ</li></ul><h1 id="Hexoæ¡†æ¶çš„ä½¿ç”¨"><a href="#Hexoæ¡†æ¶çš„ä½¿ç”¨" class="headerlink" title="Hexoæ¡†æ¶çš„ä½¿ç”¨"></a>Hexoæ¡†æ¶çš„ä½¿ç”¨</h1><ul><li>hexoå¸¸ç”¨å‘½ä»¤<ul><li><code>hexo init</code>åˆå§‹åŒ–åšå®¢</li><li><code>hexo clean</code>æ¸…ç†ç¼“å­˜æ–‡ä»¶</li><li><code>hexo g</code>ç”Ÿæˆæ–‡ä»¶</li><li><code>hexo s</code>è¿è¡Œæœ¬åœ°æœåŠ¡å™¨</li><li><code>hexo d</code>éƒ¨ç½²åˆ°æœåŠ¡å™¨</li><li><code>hexo n &quot;MyBlog&quot;</code>åˆ›å»ºæ–°çš„æ–‡ç« </li></ul></li></ul><p>ç°åœ¨æˆ‘ä»¬åªéœ€è¦åœ¨ D:\MyBlog\HexoBlog ä¸‹è¿è¡Œ<code>hexo init &amp; hexo s</code>ï¼Œåœ¨æµè§ˆå™¨ä¸­è¾“å…¥ <a href="http://localhost:4000/">localhost:4000</a> å³ä¸ºæœ€åˆå§‹çš„åšå®¢å†…å®¹ã€‚</p><h1 id="éƒ¨ç½²åšå®¢"><a href="#éƒ¨ç½²åšå®¢" class="headerlink" title="éƒ¨ç½²åšå®¢"></a>éƒ¨ç½²åšå®¢</h1><h2 id="åˆ›å»ºä»“åº“"><a href="#åˆ›å»ºä»“åº“" class="headerlink" title="åˆ›å»ºä»“åº“"></a>åˆ›å»ºä»“åº“</h2><p>ç”¨æ¥å­˜æ”¾ä½ çš„ä»£ç /ç½‘ç«™ä¾›åˆ«äººè®¿é—®</p><p><img src="/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/Untitled.png" alt="Hexoé™æ€åšå®¢æ­å»ºå’Œéƒ¨ç½²/Untitled.png"></p><p><img src="/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/Untitled%201.png" alt="Hexoé™æ€åšå®¢æ­å»ºå’Œéƒ¨ç½²/Untitled%201.png"></p><h2 id="åˆ›å»ºéƒ¨ç½²åˆ†æ”¯"><a href="#åˆ›å»ºéƒ¨ç½²åˆ†æ”¯" class="headerlink" title="åˆ›å»ºéƒ¨ç½²åˆ†æ”¯"></a>åˆ›å»ºéƒ¨ç½²åˆ†æ”¯</h2><p>masterç”¨æ¥æ”¾ä»£ç ï¼Œph-pagesç”¨æ¥éƒ¨ç½²ç½‘ç«™</p><p><img src="/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/Untitled%202.png" alt="Hexoé™æ€åšå®¢æ­å»ºå’Œéƒ¨ç½²/Untitled%202.png"></p><p><img src="/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/Untitled%203.png" alt="Hexoé™æ€åšå®¢æ­å»ºå’Œéƒ¨ç½²/Untitled%203.png"></p><h2 id="å¼€å¯Gitee-PagesæœåŠ¡"><a href="#å¼€å¯Gitee-PagesæœåŠ¡" class="headerlink" title="å¼€å¯Gitee PagesæœåŠ¡"></a>å¼€å¯Gitee PagesæœåŠ¡</h2><p><img src="/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/Untitled%204.png" alt="Hexoé™æ€åšå®¢æ­å»ºå’Œéƒ¨ç½²/Untitled%204.png"></p><h2 id="åˆ›å»ºå…¬é’¥"><a href="#åˆ›å»ºå…¬é’¥" class="headerlink" title="åˆ›å»ºå…¬é’¥"></a>åˆ›å»ºå…¬é’¥</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;é‚®ç®±åœ°å€&quot;</span></span><br></pre></td></tr></table></figure><p>å¯†é’¥å¯¹ç”Ÿæˆåé»˜è®¤çš„ä½ç½®æ˜¯åœ¨Â C:\Users\Administrator.sshÂ çš„ç›®å½•ä¸‹ã€‚</p><p>å…¶ä¸­Â id_rsaÂ æ˜¯ç§é’¥ï¼Œid_rsa.pubÂ æ˜¯å…¬é’¥ã€‚</p><p>ç”¨è®°äº‹æœ¬æ‰“å¼€å¹¶å¤åˆ¶å…¬é’¥ã€‚</p><h2 id="æ·»åŠ å…¬é’¥"><a href="#æ·»åŠ å…¬é’¥" class="headerlink" title="æ·»åŠ å…¬é’¥"></a>æ·»åŠ å…¬é’¥</h2><p><img src="/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/Untitled%205.png" alt="Hexoé™æ€åšå®¢æ­å»ºå’Œéƒ¨ç½²/Untitled%205.png"></p><p>å°†å¤åˆ¶åˆ°çš„å…¬é’¥ç²˜è´´è¿›å»å¹¶ç¡®å®šä¿å­˜ã€‚</p><h2 id="å®‰è£…hexo-deployer-git"><a href="#å®‰è£…hexo-deployer-git" class="headerlink" title="å®‰è£…hexo-deployer-git"></a>å®‰è£…hexo-deployer-git</h2><ul><li>è¿è¡Œ<code>npm install hexo-deployer-git --save</code></li></ul><h2 id="ä¿®æ”¹é…ç½®æ–‡ä»¶"><a href="#ä¿®æ”¹é…ç½®æ–‡ä»¶" class="headerlink" title="ä¿®æ”¹é…ç½®æ–‡ä»¶"></a>ä¿®æ”¹é…ç½®æ–‡ä»¶</h2><p>æ‰“å¼€D:\MyBlog\HexoBlog_config.ymlæŸ¥æ‰¾deployï¼Œå¹¶è¡Œä¿®æ”¹ä¸‹é¢è¿™æ®µä»£ç </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line"><span class="built_in">type</span>: git</span><br><span class="line">repo: https://gitee.com/NephrenCake/NephrenCake.git</span><br><span class="line">branch: ph-pages</span><br></pre></td></tr></table></figure><h2 id="éƒ¨ç½²è‡³äº‘ç«¯"><a href="#éƒ¨ç½²è‡³äº‘ç«¯" class="headerlink" title="éƒ¨ç½²è‡³äº‘ç«¯"></a>éƒ¨ç½²è‡³äº‘ç«¯</h2><ul><li>è¿è¡Œ<code>hexo d</code></li></ul><blockquote><p><a href="https://nephrencake.gitee.io/">https://nephrencake.gitee.io/</a> å³é™æ€åšå®¢çš„åœ°å€äº†ã€‚</p></blockquote><ul><li>å¦‚æœæœ‰ç½‘é¡µä¸åŒæ­¥çš„æ—¶å€™<ul><li>åœ¨Gitee Pages æœåŠ¡ä¸­æ›´æ–°éƒ¨ç½²ï¼ˆæ¯æ¬¡deployä¹‹åéƒ½è¦æ‰‹åŠ¨æ›´æ–°ï¼‰</li><li>æ¸…ç†æµè§ˆå™¨ç¼“å­˜</li></ul></li></ul><p><img src="/2021/01/Hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%92%8C%E9%83%A8%E7%BD%B2/Untitled%206.png" alt="Hexoé™æ€åšå®¢æ­å»ºå’Œéƒ¨ç½²/Untitled%206.png"></p>]]></content>
      
      
      <categories>
          
          <category> Hexoåšå®¢æ­å»º </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Butterflyä¸»é¢˜å®‰è£…å’Œé­”æ”¹</title>
      <link href="/2021/01/Butterfly%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E5%92%8C%E9%AD%94%E6%94%B9/"/>
      <url>/2021/01/Butterfly%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E5%92%8C%E9%AD%94%E6%94%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="å®‰è£…butterfly"><a href="#å®‰è£…butterfly" class="headerlink" title="å®‰è£…butterfly"></a>å®‰è£…butterfly</h1><ol><li>è¿è¡Œ<code>git clone https://github.com/jerryc127/hexo-theme-butterfly themes/butterfly</code></li><li>æ‰“å¼€_config.ymlæ‰¾åˆ°è¿™ä¸€è¡Œ<code>theme: landspace</code>ç„¶åå°†landspaceæ›¿æ¢butterfly</li><li>å®‰è£…æ’ä»¶<code>cnpm install hexo-renderer-pug hexo-renderer-stylus</code></li><li>å®‰è£…æ’ä»¶<code>cnpm install --save hexo-renderer-jade hexo-generator-feed hexo-generator-sitemap hexo-browsersync hexo-generator-archive</code></li></ol><blockquote><p>ä¸ºäº†ä»¥åå‡çº§æ–¹ä¾¿ï¼Œè¿™é‡Œä¸æ¨èç›´æ¥å¯¹ä¸»é¢˜çš„é…ç½®æ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼Œè€Œæ˜¯å¤åˆ¶é…ç½®æ–‡ä»¶è¿›è¡Œä¿®æ”¹ã€‚ä¸ªäººæ¨èæŠŠä¸»é¡Œçš„é…ç½®æ–‡ä»¶_config.ymlå¤åˆ¶åˆ° Hexo å·¥ä½œç›®å½•ä¸‹çš„source/_data/butterfly.ymlï¼Œå¦‚æœç›®å½•ä¸å­˜åœ¨é‚£å°±åˆ›å»ºä¸€ä¸ªã€‚</p></blockquote><h1 id="butterflyä¸»é¢˜é­”æ”¹"><a href="#butterflyä¸»é¢˜é­”æ”¹" class="headerlink" title="butterflyä¸»é¢˜é­”æ”¹"></a>butterflyä¸»é¢˜é­”æ”¹</h1><p>è‡ªå·±ä¸€å¼€å§‹åŠ¨æ‰‹åšçš„æ—¶å€™å¤§éƒ¨åˆ†éƒ½å‚è€ƒDreamy.TZKçš„åšå®¢</p><p><a href="https://www.antmoe.com/posts/75a6347a/index.html">Hexoå®‰è£…å¹¶ä½¿ç”¨Butterflyä¸»é¢˜</a></p><p>ä½†æ˜¯æ”¹åˆ°åæ¥å°±è¶Šæ¥è¶Šè§‰å¾—ï¼Œç‰ˆæœ¬é—®é¢˜å¯¼è‡´çš„ä¸»é¢˜ä¿®æ”¹ä¸å…¼å®¹ï¼Œé—®é¢˜å®åœ¨å¾ˆå¤§ã€‚ç”šè‡³åˆ°åæ¥æƒ³è¦è·å¾—è‡ªå·±çš„é¢„æœŸæ•ˆæœæ—¶ï¼Œå·²ç»ä¸å¾—ä¸å»åœ¨æºä»£ç ä¸Šä¸‹æ‰‹<del>ï¼Œå› ä¸ºè¿˜æ²¡æœ‰å­¦è¿‡å‰ç«¯ï¼Œæ”¹çš„å±å®é¢ç›®å…¨é</del>ã€‚</p><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><p>è¿™é‡Œåªèƒ½ä¸ºæƒ³è¦è‡ªå·±åŠ¨æ‰‹æ”¹çš„å°ä¼™ä¼´ä¸€äº›å»ºè®®ï¼Œæ¯”å¦‚æƒ³ä¿®æ”¹æ–‡ç« é¡µï¼Œå¯ä»¥ç»“åˆæµè§ˆå™¨çš„å¼€å‘è€…å·¥å…·æ¥æ‰¾åˆ°ç›¸åº”çš„å‚æ•°ï¼Œæ¥ä¿®æ”¹å¯¹åº”çš„å€¼ã€‚</p><p><img src="/2021/01/Butterfly%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E5%92%8C%E9%AD%94%E6%94%B9/Untitled.png" alt="Butterflyä¸»é¢˜å®‰è£…å’Œé­”æ”¹/Untitled.png"></p><p><img src="/2021/01/Butterfly%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E5%92%8C%E9%AD%94%E6%94%B9/Untitled%201.png" alt="Butterflyä¸»é¢˜å®‰è£…å’Œé­”æ”¹/Untitled%201.png"></p><h2 id="ç›¸å†Œçš„ä½¿ç”¨"><a href="#ç›¸å†Œçš„ä½¿ç”¨" class="headerlink" title="ç›¸å†Œçš„ä½¿ç”¨"></a>ç›¸å†Œçš„ä½¿ç”¨</h2><p><a href="https://blog.ahzoo.cn/2020/07/20/b7201/">https://blog.ahzoo.cn/2020/07/20/b7201/</a></p><h2 id="å…³äºæ–‡ç« ä¸­æ’å…¥å›¾ç‰‡"><a href="#å…³äºæ–‡ç« ä¸­æ’å…¥å›¾ç‰‡" class="headerlink" title="å…³äºæ–‡ç« ä¸­æ’å…¥å›¾ç‰‡"></a>å…³äºæ–‡ç« ä¸­æ’å…¥å›¾ç‰‡</h2><p>å…ˆæŠŠhexoçš„é…ç½®æ–‡ä»¶ä¸­çš„ relative_link å‚æ•°ç¡®ä¿ä¸ºfalseã€‚å¦åˆ™ä¼šå¯¼è‡´butterflyå„åˆ†é¡µé¢çš„é“¾æ¥é”™ä¹±</p><p><img src="/2021/01/Butterfly%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E5%92%8C%E9%AD%94%E6%94%B9/image-20201231210020980.png" alt="image-20201231210020980"></p><p>æŠŠæ¯ä¸ªæ–‡ç« å¼€å¤´éƒ¨åˆ†åŠ ä¸€ä¸ªå‚æ•° relative_link: trueã€‚ä½¿æ¯ä¸ªæ–‡ç« éƒ¨åˆ†éµä»ç›¸å¯¹ä½ç½®çš„å¼•ç”¨ï¼Œè¿™æ ·å¯ä»¥å°†æ–‡ç« çš„å›¾ç‰‡ï¼Œä¸ä»…åœ¨typoraæˆ–æ˜¯åœ¨æœåŠ¡å™¨ä¸Šï¼Œéƒ½èƒ½å¤Ÿå®æ—¶çœ‹åˆ°è‡ªå·±æ–‡ç« å›¾ç‰‡å¼•ç”¨çš„æ•ˆæœã€‚</p><p><img src="/2021/01/Butterfly%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E5%92%8C%E9%AD%94%E6%94%B9/image-20201231205840731.png" alt="image-20201231205840731"></p><p><img src="/2021/01/Butterfly%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E5%92%8C%E9%AD%94%E6%94%B9/image-20201231210339382.png" alt="image-20201231210339382"></p><h2 id="å…³äºåˆ†ç±»ç®¡ç†-postä¸‹çš„æ–‡ç« "><a href="#å…³äºåˆ†ç±»ç®¡ç†-postä¸‹çš„æ–‡ç« " class="headerlink" title="å…³äºåˆ†ç±»ç®¡ç†_postä¸‹çš„æ–‡ç« "></a>å…³äºåˆ†ç±»ç®¡ç†_postä¸‹çš„æ–‡ç« </h2><p>ä¸»è¦å‚è€ƒ<a href="https://blog.csdn.net/maosidiaoxian/article/details/85220394">å¦‚ä½•åœ¨Hexoä¸­å¯¹æ–‡ç« mdæ–‡ä»¶åˆ†ç±»</a></p><p>ç°åœ¨æ–‡ç« ä¸­çš„permalink:å‚æ•°ä¼šå®Œå…¨è¦†ç›–_config.ymlä¸­çš„è®¾ç½®ï¼Œè¦æ³¨æ„ã€‚</p><h1 id="åé¢åº”è¯¥è¿˜ä¼šæ…¢æ…¢æ›´æ–°ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿"><a href="#åé¢åº”è¯¥è¿˜ä¼šæ…¢æ…¢æ›´æ–°ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿" class="headerlink" title="åé¢åº”è¯¥è¿˜ä¼šæ…¢æ…¢æ›´æ–°ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿~"></a>åé¢åº”è¯¥è¿˜ä¼šæ…¢æ…¢æ›´æ–°ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿~</h1>]]></content>
      
      
      <categories>
          
          <category> Hexoåšå®¢æ­å»º </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
